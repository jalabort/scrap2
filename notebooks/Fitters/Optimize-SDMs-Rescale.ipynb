{
 "metadata": {
  "name": "",
  "signature": "sha256:fa12b40411f8700a5a3c68ab3f32ace129d737bea40cbe2521ffc5081349ece9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as pio\n",
      "from menpo.landmark import labeller, ibug_68_trimesh, ibug_49_points\n",
      "\n",
      "# load training images\n",
      "training_images = []\n",
      "for i in pio.import_images('/data/PhD/DataBases/lfpw/trainset/*.png', max_images=1):\n",
      "    # crop image\n",
      "    i.crop_to_landmarks_proportion(0.1)\n",
      "    # label it\n",
      "    labeller(i, 'PTS', ibug_68_trimesh)\n",
      "    # convert it to grayscale if needed\n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='luminosity')\n",
      "    # append it to the list\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import deepcopy\n",
      "\n",
      "img = deepcopy(training_images[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#img.constrain_mask_to_landmarks(group='PTS')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "img.rescale(0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i1 = img.rescale(0.1)\n",
      "i1.landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "img.rescale2(0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i2 = img.rescale2(0.1)\n",
      "i2.landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "img.features.hog(mode='sparse', constrain_landmarks=False).glyph().view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numpy.testing import assert_allclose\n",
      "\n",
      "breaking_bad = pio.import_builtin_asset('breakingbad.jpg')\n",
      "breaking_bad.crop_to_landmarks(boundary=20)\n",
      "breaking_bad.constrain_mask_to_landmarks()\n",
      "hog = breaking_bad.features.hog(mode='sparse', constrain_landmarks=False)\n",
      "x = np.where(hog.landmarks['PTS'].lms.points[:, 0] > hog.shape[1] - 1)\n",
      "y = np.where(hog.landmarks['PTS'].lms.points[:, 0] > hog.shape[0] - 1)\n",
      "assert_allclose(len(x[0]) + len(y[0]), 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hog.landmarks['PTS'].view(channels=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img.rescale2(0.5).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import deepcopy\n",
      "\n",
      "img = deepcopy(training_images[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img.rescale(0.5).view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.transform import rescale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "rescale(img.pixels, scale=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pythonic way of converting to list if we are passed a single float\n",
      "try:\n",
      "    if len(scale) < self.n_dims:\n",
      "        raise ValueError(\n",
      "            'Must provide a scale per dimension.'\n",
      "            '{} scales were provided, {} were expected.'.format(\n",
      "                len(scale), self.n_dims\n",
      "            )\n",
      "        )\n",
      "except TypeError:  # Thrown when len() is called on a float\n",
      "    scale = [scale] * self.n_dims\n",
      "\n",
      "# Make sure we have a numpy array\n",
      "scale = np.asarray(scale)\n",
      "for s in scale:\n",
      "    if s <= 0:\n",
      "        raise ValueError('Scales must be positive floats.')\n",
      "\n",
      "transform = NonUniformScale(scale)\n",
      "from menpo.image.boolean import BooleanImage\n",
      "# use the scale factor to make the template mask bigger\n",
      "template_mask = BooleanImage.blank(transform.apply(self.shape),\n",
      "                                   round=round)\n",
      "# due to image indexing, we can't just apply the pseduoinverse\n",
      "# transform to achieve the scaling we want though!\n",
      "# Consider a 3x rescale on a 2x4 image. Looking at each dimension:\n",
      "#    H 2 -> 6 so [0-1] -> [0-5] = 5/1 = 5x\n",
      "#    W 4 -> 12 [0-3] -> [0-11] = 11/3 = 3.67x\n",
      "# => need to make the correct scale per dimension!\n",
      "shape = np.array(self.shape, dtype=np.float)\n",
      "# scale factors = max_index_after / current_max_index\n",
      "# (note that max_index = length - 1, as 0 based)\n",
      "scale_factors = (scale * shape - 1) / (shape - 1)\n",
      "inverse_transform = NonUniformScale(scale_factors).pseudoinverse\n",
      "# for rescaling we enforce that mode is nearest to avoid num. errors\n",
      "if 'mode' in kwargs:\n",
      "    raise ValueError(\"Cannot set 'mode' kwarg on rescale - set to \"\n",
      "                     \"'nearest' to avoid numerical errors\")\n",
      "kwargs['mode'] = 'nearest'\n",
      "# Note here we pass warp_mask to warp_to. In the case of\n",
      "# Images that aren't MaskedImages this kwarg will\n",
      "# harmlessly fall through so we are fine.\n",
      "return self.warp_to(template_mask, inverse_transform,\n",
      "                    warp_landmarks=True,\n",
      "                    interpolator=interpolator, **kwargs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.image import Image\n",
      "from menpo.transform import UniformScale\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "\n",
      "downscale = 0.5\n",
      "\n",
      "\n",
      "image_data = rescale(img.pixels, scale=downscale)\n",
      "# rescale and reassign existent landmark\n",
      "image = Image(image_data)\n",
      "image.landmarks = img.landmarks\n",
      "transform = UniformScale(downscale, img.n_dims)\n",
      "transform.apply_inplace(image.landmarks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit \n",
      "img.rescale(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img.rescale(2).landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}