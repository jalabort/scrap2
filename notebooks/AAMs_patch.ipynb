{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1. Load Training Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug.image import RGBImage, MaskedNDImage\n",
      "\n",
      "images = auto_import('/Users/joan/PhD/DataBases/lfpw/trainset/*.png')\n",
      "images = [i.as_greyscale() if type(i) is RGBImage else i for i in images]\n",
      "\n",
      "new_images = []\n",
      "for i in images:\n",
      "    img = MaskedNDImage(i.pixels)\n",
      "    img.landmarks = i.landmarks\n",
      "    new_images.append(img)\n",
      "images = new_images\n",
      "\n",
      "del new_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2. Build AAMs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.activeappearancemodel import aam_builder, AAM\n",
      "from pybug.transform.tps import TPS\n",
      "from pybug.landmark import ibug_68_trimesh\n",
      "\n",
      "options = {'features': {'type': , 'options': {'kwargs': None}},\n",
      "           'patches': True,\n",
      "           'patch_size': [32, 32],\n",
      "           'transform_cls': TPS,\n",
      "           'reference_frame_boundary': 20,\n",
      "           'max_shape_components': 25,\n",
      "           'max_appearance_components': 250}\n",
      "\n",
      "aam = aam_builder(images, **options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3. View Instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aam.instance(np.random.randn(20), np.random.randn(200), transform_cls=TPS, patch_size=[32, 32], patches=True, level=2).view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4. Load Test Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the training images of the LFPW database as landmarked images using the autoimporter\n",
      "images = auto_import('/Users/joan/PhD/DataBases/lfpw/testset/*.png')\n",
      "images = [i.as_greyscale() if type(i) is RGBImage else i for i in images]\n",
      "\n",
      "new_images = []\n",
      "for i in images:\n",
      "    img = MaskedNDImage(i.pixels)\n",
      "    img.landmarks = i.landmarks\n",
      "    new_images.append(img)\n",
      "images = new_images\n",
      "\n",
      "del new_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 5. Fit AAM to Test Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.tps import TPS\n",
      "\n",
      "aam.initialize_lk(n_shape=[3, 6, 12], n_appearance=[200, 200, 200], transform_cls=TPS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_transforms = aam.lk_fit_annotated_database(images, runs=1, noise_std=0.0, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 6. Evaluate Performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.activeappearancemodel.accuracy import plot_ced\n",
      "from pybug.transform.affine import UniformScale\n",
      "from __future__ import division\n",
      "\n",
      "original_landmarks = [i.landmarks['PTS'].lms for i in images]\n",
      "\n",
      "fitted_landmarks = []\n",
      "for ft in fitted_transforms:\n",
      "    for f in ft:\n",
      "        fitted_landmarks.append(UniformScale(1,2).apply(f[-1].target))\n",
      "\n",
      "errors = plot_ced(fitted_landmarks, original_landmarks, label='AIC')[0]\n",
      "\n",
      "fitted_landmarks = []\n",
      "for ft in fitted_transforms:\n",
      "    for f in ft:\n",
      "        fitted_landmarks.append(UniformScale(2,2).apply(f[-2].target))\n",
      "\n",
      "plot_ced(fitted_landmarks, original_landmarks, label='AIC')\n",
      "\n",
      "fitted_landmarks = []\n",
      "for ft in fitted_transforms:\n",
      "    for f in ft:\n",
      "        fitted_landmarks.append(UniformScale(4,2).apply(f[-3].target))\n",
      "\n",
      "plot_ced(fitted_landmarks, original_landmarks, label='AIC');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.count_nonzero(np.array(errors) < 0.03) / len(images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind = 0\n",
      "images[ind].landmarks['fitted_0'].view()\n",
      "gcf().set_size_inches((10,10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}