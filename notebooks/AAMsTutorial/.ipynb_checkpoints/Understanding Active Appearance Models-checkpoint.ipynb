{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:9ad189869c257da1820bacc22680eceb14d06712a9e1215e245d9d3b9b19f41b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Understanding Active Appearance Models\n",
      "---\n",
      "\n",
      "## i\u00b7BUG group tutorial\n",
      "\n",
      "### Joan Alabort-i-Medina \n",
      "<ja310@imperial.ac.uk>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Part 1: Building Active Appearance Models\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_number": 3
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "> \"**Active Apperance Models (AAMs)** are **non-linear**, **generative**, and **parametric** models of a certain visual phenomenon\". \n",
      "\n",
      "> <div align=\"right\"><font size=\"2\">I. Matthews and S. Baker, 2004.</font></div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 4
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- **non-linear**: they are non-linear in terms of *pixel intensities*.\n",
      "\n",
      "- **generative**: they generate images of a particular *object* class (e.g. the human face).\n",
      "\n",
      "- **parametric**: they are *controlled* by a set of parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.visualize import visualize_aam\n",
      "from alabortcvpr2015.utils import pickle_load\n",
      "\n",
      "aam = pickle_load('/Users/joan/PhD/Models/aam_int.menpo')\n",
      "\n",
      "visualize_aam(aam)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 5,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 5,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "A bit of history...\n",
      "\n",
      "They were originally proposed in **1998** by G. Edwards, C. J. Taylor, and T. F. Cootes from Department of Medical Biophysics (**not Computing!**) at University of Manchester.\n",
      "\n",
      "- *G. Edwards, C. J. Taylor, and T. F. Cootes, \"Interpreting face images using active appearance models\". FG 1998*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 7
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Luckily for the original authors quite a lot of research stemmed from the original paper:\n",
      "\n",
      "- *T. F. Cootes, K. Walker, and C. J. Taylor, \u201cView-based active appearance models,\u201d in FG, 2000*\n",
      "- *T. F. Cootes, G. J. Edwards, and C. J. Taylor, \u201cActive appearance models,\u201d TPAMI, 2001*.\n",
      "- *T. F. Cootes and C. J. Taylor, \u201cOn representing edge structure for model matching,\u201d in CVPR, 2001*\n",
      "- *I. Matthews and S. Baker, \u201cActive appearance models revisited,\u201d IJCV, 2004*.\n",
      "- *R. Gross, I. Matthews, and S. Baker, \u201cGeneric vs. person specific active appearance models,\u201d IVC, 2005.*\n",
      "- *A. U. Batur and M. H. Hayes, \u201cAdaptive active appearance models,\u201d TIP, 2005*.\n",
      "- *G. Papandreou and P. Maragos, \u201cAdaptive and constrained algorithms for inverse compositional active appearance model fitting,\u201d CVPR, 2008*.\n",
      "- *J. Saragih and R. Gocke, \u201cLearning aam fitting through simulation,\u201d PR, 2009*.\n",
      "- *B. Amberg, A. Blake, and T. Vetter, \u201cOn compositional image alignment, with an application to active appearance models,\u201d CVPR, 2009*.\n",
      "- *G. Tzimiropoulos, J. Alabort-i-Medina, S. Zafeiriou, and M. Pantic. \"Generic active appearance models revisited\". ACCV, 2012*.\n",
      "- *G. Tzimiropoulos and M. Pantic. \"Optimization problems for fast aam fitting in-the-wild\". ICCV, 2013*.\n",
      "- *G. Tzimiropoulos and M. Pantic. \"Gauss-Newton deformable part models for face alignment in-the-wild\". CVPR, 2014*.\n",
      "- *J. Alabort-i-Medina and S. Zafeiriou. \"Bayesian active appearance models\". CVPR, 2014.*\n",
      "- *E. Antonakos, J. Alabort-i-Medina, G. Tzimiropoulos, and S. Zafeiriou. \"HOG active appearance models\". ICIP 2014*.\n",
      "- *J. Kossaifi, G. Tzimiropoulos, M. Pantic. \"Fast Newton Active Appearance Models\". ICIP, 2014*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 8
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- *J. Alabort-i-Medina, E. Antonakos, J. Booth, P. Snape, S. Zafeiriou. \"Menpo: A Comprehensive Platform for Parametric Image Alignment and Visual Deformable Models\". ACM Multimedia, Open Source Software Competition, 2014.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 8,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "although, (typically) linear in terms of both shape and texture, the image formation process is non-linear in terms of *pixel intensities*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 8,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "To get us started with AAMs, we will assume that the object we are interested in modelling is no other than the **human face**:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 11
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "![Alt text](http://static.comicvine.com/uploads/original/14/145290/3282321-5672922306-32822.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 12
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The first thing we will need is a **large** collection of face images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.landmark import labeller, ibug_face_66\n",
      "\n",
      "images = []\n",
      "for i  in mio.import_images('/Users/joan/PhD/DataBases/faces/lfpw/trainset/', \n",
      "                            max_images=None, verbose=True):\n",
      "    \n",
      "    i.crop_to_landmarks_proportion_inplace(0.5)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(100)\n",
      "    labeller(i, 'PTS', ibug_face_66)\n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='luminosity')\n",
      "    \n",
      "    images.append(i)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 13
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.visualize import visualize_images\n",
      "\n",
      "visualize_images(images)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 14
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 15
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Wait a moment... What are these points!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 16
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Fair enough, I kind of lied before... \n",
      "\n",
      "What we really need is a large collection of carefully ** annotated** face images."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 17
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The previous annotations try to encode the notion face **shape**...\n",
      "\n",
      "> A shape is the form of an object or its external boundary, outline, or external surface, as opposed to other properties such as colour, texture or material composition.\n",
      "\n",
      "> <div align=\"right\"><font size=\"2\">Wikipedia</font></div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 18
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "...by consistently identifying the positions of a small set of **landmarks** defining the faces in all images. \n",
      "\n",
      "> In morphometrics, landmark point or shortly landmark is a point in a shape object in which correspondences between and within the populations of the object are preserved.\n",
      "\n",
      "> <div align=\"right\"><font size=\"2\">Wikipedia</font></div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 19
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Mathematically, a shape can be defined as:\n",
      "\n",
      "$$\\mathbf{s} = (x_1, y_1, \\cdots, x_v, y_v)^T \\in \\mathcal{R}^{2v \\times 1}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.visualize import visualize_shapes\n",
      "\n",
      "visualize_shapes([i.landmarks for i in images])"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 20,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 20,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "In AAMs, images of a particular object are generated by combining **linear models** describing the **shape** and **texture** of the object using a specific **motion** model (also referred to as *the warp*)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 22
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Let us start by *formally* defining the **shape model**:\n",
      "\n",
      "$$\\mathbf{s} = \\bar{\\mathbf{s}} + \\sum_{i=1}^{n_s} p_i \\mathbf{s}_i = \\bar{\\mathbf{s}} + \\mathbf{S} \\mathbf{p}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 23
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "where: \n",
      "\n",
      "$$\\bar{\\mathbf{s}} = (\\bar{x_1}, \\bar{y_1}, \\cdots, \\bar{x_v}, \\bar{y_v})^T\\in \\mathcal{R}^{2v}$$\n",
      "\n",
      "$$\\mathbf{p} = (p_1, \\cdots, p_{n_s})^T \\in \\mathcal{R}^{n_s}$$\n",
      "\n",
      "$$\\mathbf{S} = (\\mathbf{s}_1, \\cdots, \\mathbf{s}_{n_s} )\\in \\mathcal{R}^{2v \\, \\times \\, n_s}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 24
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The previous shape model can be learned by applying **Principal Component Analysis (PCA)** to the set of manually annotated points defining the object shape in the images (usually after registering all shapes using **Procrustes Analysis**).  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.transform import Translation, GeneralizedProcrustesAnalysis\n",
      "from menpo.model import PCAModel\n",
      "\n",
      "# extract shapes from images\n",
      "shapes = [i.landmarks['ibug_face_66'].lms for i in images] \n",
      "\n",
      "# centralize shapes\n",
      "centered_shapes = [Translation(-s.centre()).apply(s) for s in shapes]\n",
      "# align centralized shape using Procrustes Analysis\n",
      "gpa = GeneralizedProcrustesAnalysis(centered_shapes)\n",
      "aligned_shapes = [s.aligned_source() for s in gpa.transforms]\n",
      "\n",
      "# build shape model\n",
      "shape_model = PCAModel(aligned_shapes)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 25
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.visualize import visualize_shape_model\n",
      "\n",
      "visualize_shape_model(shape_model)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 26,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 26,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Note that because the shapes were normalized using Procrustes Analysis before we applied PCA, the previous shape model has mainly learned **nonrigid** facial deformations and lacks the ability of placing shapes at arbitrary positions on the image plane."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 28
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Luckly, this problem can be solved by composing the model with a 2d similarity transform:\n",
      "\n",
      "$$\\mathbf{x} = s \\mathbf{R} \\left( \\bar{\\mathbf{x}} + \\sum_{i=1}^{n_s} p_i \\mathbf{x}_i \\right) +\\mathbf{t}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 29
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "where:\n",
      "\n",
      "$$\\mathbf{x} = (x_i, y_i)^T \\in \\mathcal{R}^{2}$$\n",
      "\n",
      "$$s \\in \\mathcal{R}$$\n",
      "\n",
      "$$\\mathbf{R} \\in \\mathcal{R}^{2 \\, \\times \\, 2}$$\n",
      "\n",
      "$$\\mathbf{t} = (t_x, t_y)^T \\in \\mathcal{R}^{2}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 30
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Luckily after some clever reparameterization (Matthews and Baker, 2004) the shape model can still be concisely expressed as before:\n",
      "\n",
      "$$\\mathbf{s} = \\bar{\\mathbf{s}} + \\sum_{i=1}^{4} p^*_i \\mathbf{s}^*_i + \\sum_{i=1}^{n_s} p_i \\mathbf{s}_i = \\bar{\\mathbf{s}} + \\mathbf{S}^* \\mathbf{p}^* + \\mathbf{S} \\mathbf{p} = \\bar{\\mathbf{s}} + \\tilde{\\mathbf{S}} \\tilde{\\mathbf{p}}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 31
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "where:\n",
      "\n",
      "$$\\mathbf{p}^* = (p^*_1, \\cdots,  p^*_4)^T \\in \\mathbf{R}^{4}$$\n",
      "\n",
      "$$\\mathbf{S}^* = (s^*_1, \\cdots, s^*_4)^T \\in \\mathbf{R}^{2v \\, \\times \\, 4}$$\n",
      "\n",
      "$$\\mathbf{s}^*_1 = \\bar{\\mathbf{s}} \\in \\mathbf{R}^{2v}$$\n",
      "\n",
      "$$\\mathbf{s}^*_2 = (-y_1, x_1, \\cdots, -y_v, x_v)^T \\in \\mathbf{R}^{2v}$$\n",
      "\n",
      "$$\\mathbf{s}^*_3 = (1, 0, \\cdots, 1, 0)^T \\in \\mathbf{R}^{2v}$$\n",
      "\n",
      "$$\\mathbf{s}^*_4 = (0, 1, \\cdots, 0, 1)^T \\in \\mathbf{R}^{2v}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from menpo.transform import AlignmentSimilarity\n",
      "from menpo.model import MeanInstanceLinearModel\n",
      "from menpofit.modelinstance import OrthoPDM\n",
      "\n",
      "# get shape model mean as numpy array\n",
      "shape_vector = shape_model.mean().as_vector()\n",
      "\n",
      "# initialize S star\n",
      "S_star = np.zeros((4, shape_vector.shape[0]))\n",
      "# first column is the mean\n",
      "S_star[0, :] = shape_vector  # Comp. 1 - just the mean\n",
      "# second column is the rotated mean\n",
      "rotated_ccw = shape_model.mean().points[:, ::-1].copy()  # flip x,y -> y,x\n",
      "rotated_ccw[:, 0] = -rotated_ccw[:, 0]  # negate (old) y\n",
      "S_star[1, :] = rotated_ccw.flatten()  # C2 - the mean rotated 90 degs\n",
      "# third column\n",
      "S_star[2, ::2] = 1  # Tx\n",
      "# fourth column\n",
      "S_star[3, 1::2] = 1  # Ty\n",
      "\n",
      "# build 2d similarity model\n",
      "sim_2d_model = MeanInstanceLinearModel(S_star, shape_vector, shape_model.mean())\n",
      "\n",
      "# orthogonalize and compose 2d similarity model with original shape model\n",
      "augmented_sm = shape_model.copy()\n",
      "augmented_sm.orthonormalize_against_inplace(sim_2d_model)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 32
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visualize_shape_model(augmented_sm)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 33
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.transform import DifferentiableAlignmentSimilarity\n",
      "from menpofit.modelinstance import OrthoPDM\n",
      "\n",
      "augmented_sm = OrthoPDM(shape_model, AlignmentSimilarity)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 34
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visualize_shape_model(augmented_sm.model)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 35,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 35,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "So far, so good ;-) \n",
      "\n",
      "Apart from that las bit..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 37
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Let us now switch our attention to the **appearance model**. \n",
      "\n",
      "We will shortly see how the appearance model is also learned using PCA. However, in order to be able to apply PCA we first need to introduce the **motion model** and the concept of **shape-free textures**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 38
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "PCA can only be applied in a particular vector space or, in other words, all vectors to which we want to apply PCA to must have the **same** lenght."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 39
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This is clearly not the case for the face images we just loaded:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'image 0 is:', images[0]\n",
      "print 'image 1 is:', images[1]"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 40
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 41
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We could resize all images to a particular resolution but that is very likely to arbitrarily modify their original aspect ratio and include a lot of backgorund information (even if images were tighly cropped)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 42
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Instead, the idea is to make use of the annotated landmarks (which are a requirement) to **define** the face appearance region in each image and **map** it to the same vector space. \n",
      "\n",
      "This can be done by:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 43
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Defining a **reference image frame** (typically build using the shape model mean shape)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 44
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Warping all images to the previous reference frame by using a **non-linear warping function**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 45
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The non-linear warping function is referred to as the **motion model** and typical choices for this function include **Piece Wise Affine** and **Thin Plate Splines** warps.\n",
      "\n",
      "Once all images have been warped onto the reference frame they all have the same dimensionality (i.e. they all have the same number of pixels) and we are ready to apply PCA.\n",
      "\n",
      "Note that, after they have being warped, all images also **share** the same face shape and hence the name **shape-free textures**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 46
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "A shape free texture can be mathematically defined using the following expression:\n",
      "\n",
      "$$\\mathcal{vec}\\left(I(\\mathcal{W}(\\mathbf{x}; \\mathbf{p}))\\right) = \\mathbf{t}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.transform import PiecewiseAffine\n",
      "from menpofit.aam.builder import build_reference_frame \n",
      "\n",
      "# build reference frame\n",
      "reference_frame = build_reference_frame(shape_model.mean())\n",
      "reference_shape = reference_frame.landmarks['source'].lms\n",
      "\n",
      "# build PiecewiseAffine transforms\n",
      "transforms = [PiecewiseAffine(reference_shape, s) for s in shapes]\n",
      "\n",
      "# warp images\n",
      "warped_images = []\n",
      "for (i, t) in zip(images, transforms):\n",
      "    wi = i.warp_to_mask(reference_frame.mask, t) \n",
      "    wi.landmarks = reference_frame.landmarks\n",
      "    warped_images.append(wi)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 47
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visualize_images(warped_images)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 48,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 48,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "After defining the motion model and introducing the concept of shape-free textures, we are now ready to *formally* define the appearance model: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 50
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\\mathbf{a} = \\bar{\\mathbf{a}} + \\sum_{i=1}^{n_a} c_i \\mathbf{a}_i = \\bar{\\mathbf{a}} + \\mathbf{A} \\mathbf{c}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 51
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "where:\n",
      "\n",
      "$$\\bar{\\mathbf{a}} = (\\bar{a_1}, \\cdots, \\bar{a_d})^T\\in \\mathcal{R}^{d}$$\n",
      "\n",
      "$$\\mathbf{c} = (c_1, \\cdots, c_{n_t})^T \\in \\mathcal{R}^{n_t}$$\n",
      "\n",
      "$$\\mathbf{A} = (\\mathbf{a}_1, \\cdots, \\mathbf{a}_{n_s} )\\in \\mathcal{R}^{d \\, \\times \\, n_t}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "appearance_model = PCAModel(warped_images)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 52
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.visualize import visualize_appearance_model\n",
      "\n",
      "visualize_appearance_model(appearance_model)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 53,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 53,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Well done!!! We have now almost covered the basics concepts defining **Active Appearance Models**.\n",
      "\n",
      "Only one bit is missing, and that is how to combine the previous three models (**shape**,  **appearance** and **motion**) so that we can effectively generate novel face images using AAMs.\n",
      "\n",
      "And the answer is:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 55
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Generate a novel **shape instance**:\n",
      "\n",
      "$$\\mathbf{s} = \\bar{\\mathbf{s}} + \\mathbf{S} \\mathbf{p}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 56
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Generate a novel **appearance instance** and rearrange it back onto a shape-free texture form:\n",
      "\n",
      "$$\\mathbf{a} = \\bar{\\mathbf{a}} + \\mathbf{A} \\mathbf{c}$$\n",
      "\n",
      "$$A(x) = \\mathcal{matrix} \\left( \\mathbf{a} \\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 57
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- **Warp** the shape-free appearance intance onto the shape instance using the motion model:\n",
      "    \n",
      "$$A(\\mathcal{W}(\\mathbf{x}, p)) = I(\\mathbf{x})$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# choose shape parameters at random\n",
      "p = np.random.randn(shape_model.n_components) * np.sqrt(shape_model.eigenvalues)\n",
      "# generate shape instance\n",
      "s = shape_model.instance(p)\n",
      "\n",
      "# define image frame containing shape instance\n",
      "I = build_reference_frame(s)\n",
      "landmarks = I.landmarks['source'].lms"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 58
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I.view_landmarks(group='source', render_numbering=False)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 59
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# choose appearance parameters at random\n",
      "c = np.random.randn(appearance_model.n_components) * np.sqrt(appearance_model.eigenvalues)\n",
      "# generate shape instance\n",
      "A = appearance_model.instance(c)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 60
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A.view()"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 61
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute PiecewiseAffine transform\n",
      "transform = PiecewiseAffine(landmarks, A.landmarks['source'].lms)\n",
      "\n",
      "I = A.warp_to_mask(I.mask, transform, warp_landmarks=True)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 62
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I.view_landmarks(group='source', render_numbering=False)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 63,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 63,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Things to take with you from this first part:\n",
      "\n",
      "- AAMs are **non-linear**, **generative**, and **parametric** models of visual phenomena.\n",
      "\n",
      "- They consists of three different sub-models:\n",
      "  - **Shape** model\n",
      "  - **Appearance** model\n",
      "  - **Motion** model\n",
      "\n",
      "- Shape and appearance models are **linear** models learned from annotated training data using **PCA**.\n",
      "\n",
      "- The motion model **non-linearly** relates the shape and appearance models and is itself an essential part of the AAM formulation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 65,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 65,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Part 2: Fitting Active Appearance Models\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 67
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "AAMs were originally developed for solving **non-rigid object alignment** problems. And up until now they remain quite popular in the domains of *face alignment* and *medical image registration*.\n",
      "\n",
      "As we did in part one, we will find it useful to restrict the problem to the domain faces, i.e. we will use AAMs to specifically tackle the **face alignment** problem. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 68
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Let us start by defining the problem:\n",
      "\n",
      "> Fitting an Active Appearance Model consists of finding the optimal parameters for which its shape and appearance models accurately describe the object being modelled in a particular image.\n",
      "\n",
      "> <div align=\"right\"><font size=\"2\">This definition is mine! :-)</font></div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 69
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Note that the only available information at fitting time is: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 70
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The input **image** which we want to fit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load image\n",
      "img = mio.import_image('/Users/joan/PhD/DataBases/faces/lfpw/testset/image_0001.png')\n",
      "\n",
      "# pre-processing\n",
      "img.crop_to_landmarks_proportion_inplace(0.5)\n",
      "img = img.rescale_landmarks_to_diagonal_range(100)\n",
      "labeller(img, 'PTS', ibug_face_66)\n",
      "if img.n_channels == 3:\n",
      "    img = img.as_greyscale(mode='luminosity')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 71
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img.view()"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 72
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 73
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- An **initial guess** for the face shape."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.base import noisy_align\n",
      "\n",
      "# noisy aligned the shape model's mean with the ground truth\n",
      "transform = noisy_align(shape_model.mean(), \n",
      "                        img.landmarks['ibug_face_66'].lms)\n",
      "initial_shape = transform.apply(shape_model.mean())\n",
      "\n",
      "# add the initial shape as landmarks to the image\n",
      "img.landmarks['initial_guess'] = initial_shape"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 74
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img.view_landmarks(group='initial_guess', render_numbering=False);"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 75
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 76
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The **AAM** that we will use to fit the image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alabortijcv2015.utils import pickle_load\n",
      "from menpofit.visualize import visualize_aam\n",
      "\n",
      "aam = pickle_load('/Users/joan/PhD/Models/aam_int.menpo')\n",
      "\n",
      "visualize_aam(aam)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 77,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 77,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The problem of fitting AAMs to input images can be *formally* defined as:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 79
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\\mathbf{p}_o, \\mathbf{c}_o = \\underset{\\mathbf{p}, \\mathbf{c}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2}\\sum_{\\mathbf{x} \\in \\Omega} \\left\\| I(\\mathcal{W}(\\mathbf{x}; \\mathbf{p})) -  \\bar{A}(\\mathbf{x}) + \\sum_{i=1}^{n_s} \\mathbf{c}_i A_i(\\mathbf{x}) \\right\\|^2 $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 80
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "which can be concisely rewritten in vector form as:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 81
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\\mathbf{p}_o, \\mathbf{c}_o = \\underset{\\mathbf{p}, \\mathbf{c}}{\\mathrm{arg\\,min\\;}} \\, \\mathcal{f}(\\mathbf{p}, \\mathbf{c}) = \\underset{\\mathbf{p}, \\mathbf{c}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right\\|^2 $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 82
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Therefore, fitting an AAM to novel image consists of finding the optimal shape and appearance parameters for which the previous expression is minimized.\n",
      "\n",
      "Note that:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 83
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The shape parameters control the way in which the input image is warped."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 84
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The reconstruction error of the warped input image by the appearance model is the quantity to be minimized and, consequently, is what drives the optimization."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 85,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Ideally, the reconstruction error should be minimized when the shape parameters correctly place the face landmarks onto the input image. \n",
      "    \n",
      "    When that happens, the input image is correctly warped onto the reference frame and its appearance model reconsturction should be optimal (hence, the error minimized)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 85,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Let us define the residual:\n",
      "\n",
      "$$ \\mathbf{r}(\\mathbf{p}, \\mathbf{c}) = \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 87
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "note that the problem can now also be written as:\n",
      "    \n",
      "$$\\mathbf{p}_o, \\mathbf{c}_o = \\underset{\\mathbf{p}, \\mathbf{c}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\mathbf{r}(\\mathbf{p}, \\mathbf{c})^T \\mathbf{r}(\\mathbf{p}, \\mathbf{c}) $$\n",
      "\n",
      "or\n",
      "\n",
      "$$\\mathbf{b}_o = \\underset{\\mathbf{b}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\mathbf{r}(\\mathbf{b})^T \\mathbf{r}(\\mathbf{b}) \\quad \\text{where} \\quad \\mathbf{b} = (\\mathbf{p}^T, \\mathbf{c}^T)^T$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 88
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can see that the residual is **linear** with respect to the appearance parameters but **nonlinear** with respect to shape parameters through the motion model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 89
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "If the residual was linear with respect to both shape and appearance parameters, the previous optimization problem would reduce to a linear least squares problems. The problem would then have a closed-form solution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 90,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Unfortunately this is not the case and fitting AAMs involves solving a **non-linear least squares** problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 90,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The most common way of solving the previous problem is by using the **Gauss-Newton** algorithm:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 92
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "1) Perform a **first order** Taylor expansion of the residual:\n",
      "    \n",
      "$$ \\mathbf{r}(\\mathbf{b} + \\Delta \\mathbf{b}) \\approx \\mathbf{r}(\\mathbf{b}) + \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}} \\Delta \\mathbf{b} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 93
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "2) **Plug it** into the cost function:\n",
      "    \n",
      "$$ \\mathcal{f}(\\mathbf{b}, \\Delta \\mathbf{b}) = \\frac{1}{2} \\left\\| \\mathbf{r}(\\mathbf{b}) + \\frac{\\partial \\mathbf{r}^T}{\\partial \\mathbf{b}} \\Delta \\mathbf{b} \\right\\|^2$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 94
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "3) Solve for the **increments** on the parameters:\n",
      "\n",
      "$$\\Delta \\mathbf{b}_o = \\underset{\\mathbf{b}}{\\mathrm{arg\\,min\\;}} \\, \\mathcal{f}(\\Delta \\mathbf{b}) = \\underset{\\mathbf{b}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\left\\| \\mathbf{r}(\\mathbf{b}) + \\frac{\\partial \\mathbf{r}^T}{\\partial \\mathbf{b}} \\Delta \\mathbf{b} \\right\\|^2 $$\n",
      "    \n",
      "$$\\frac{\\partial\\mathcal{f}}{\\partial\\Delta\\mathbf{b}} = \\frac{\\partial \\left(\\frac{1}{2} \\left\\| \\mathbf{r}(\\mathbf{b}) + \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}} \\Delta \\mathbf{b} \\right\\|^2\\right)}{\\partial\\Delta\\mathbf{b}} = \\left( \\mathbf{r}(\\mathbf{b}) + \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}} \\Delta \\mathbf{b} \\right) \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}}^T =0$$\n",
      "    \n",
      "$$\\Delta \\mathbf{b} = - \\left( \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}}^T \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}} \\right)^{-1} \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}}^T \\mathbf{r}(\\mathbf{b})$$\n",
      "\n",
      "$$\\Delta \\mathbf{b} = - \\mathbf{R} \\mathbf{r}(\\mathbf{b}) \\quad \\text{where} \\quad \\mathbf{R} = \\left( \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}}^T \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}} \\right)^{-1} \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}}^T$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 95
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "4) Update the parameters using the following **update rule**:\n",
      "    \n",
      "$$\\mathbf{b}_k \\leftarrow \\mathbf{b}_{k-1} + \\mathbf{\\Delta\\mathbf{b}}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 96
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "5) If not **converged**, go to 1.\n",
      "    \n",
      "$$ \\left\\| \\mathbf{b}_k - \\mathbf{b}_{k-1} \\right\\|^2 < \\text{tol} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 97
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Note that other algorithms have also been used to fit AAMs:\n",
      "    \n",
      "- **Steepest Descent** algorithm (Amberg et al. 2009)\n",
      "- **Newton** algorithm (Kossaifi et al. 2014)\n",
      "- **Efficient Second Order Methods** (hopefully, my next paper if I ever finish it...)\n",
      "\n",
      "There derivations are slightly different but very related to the Gauss-Newton one. For more details on these algorithms I refer you to the previous papers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 98,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Or... we can always try to quickly derive them on the whiteboard..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 98,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "At this point we will concetrate on the previous Gauss-Newton algorithm and, in particular, look at two different techniques that one can use to compute the derivative of the residual with respect to the parameters.\n",
      "\n",
      "Note that, in principle, the derivative depends on the parameters and needs to be **recomputed** at each iteration of the Gauss-Newton algorithm and so does its pseudo-inverse:\n",
      "\n",
      "$$\\mathbf{R}(\\mathbf{b}) = \\left( \\frac{\\partial \\mathbf{r}(\\mathbf{b})}{\\partial \\mathbf{b}}^T \\frac{\\partial \\mathbf{r}(\\mathbf{b})}{\\partial \\mathbf{b}} \\right)^{-1} \\frac{\\partial \\mathbf{r}(\\mathbf{b})}{\\partial \\mathbf{b}}^T$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 100
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- **Numerical approximation**:\n",
      "\n",
      "This is the approach proposed in the original paper AAM paper (Edwards et al. 1998)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 101
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Remember the definition of derivative from those glorious high school days...\n",
      "\n",
      "$$f^\\prime(a) = \\underset{h \\rightarrow 0}{\\lim} \\frac{f(a+h) - f(a)}{h}$$\n",
      "\n",
      "which can be approximated by:\n",
      "\n",
      "$$m = \\frac{\\text{change in} \\,\\, f(x)}{\\text{change in} \\,\\, x} = \\frac{\\Delta f(x)}{\\Delta x}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 102
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "So that is the basis for numerically approximating the derivative of the residual with respect to the parameters:\n",
      "\n",
      "$$\\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{b}_i} \\approx \\frac{1}{NN_p}\\sum_{j=1}^N \\sum_{k=1}^{N_p} \\frac{\\mathbf{r}_j(\\tilde{\\mathbf{b}}_i^k) - \\mathbf{r}_j(\\mathbf{b}_i^*)}{\\tilde{\\mathbf{b}}_i^k -\\mathbf{b}_i^*} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 103
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This is a **linear** approximation to the derivative learned from training data by perturbing the residuals around the optimal values for the parameters.\n",
      "\n",
      "In the original paper the authors used a **combined-AAM** formulation which greatly reduces the total number of parameters for which the derivative needs to be estimated. However the same approximation can also be used for the **independent-AAMs** described in this tutorial."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 103
      },
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "The biggest advantage of this approach is the fact that the derivative is only estimated once from training data and considered **fixed** throughout the optimization. Consequently, in this case, the derivative of the residual with respect to the parameters does not need to be re-estimated at each iteration of the Gauss-Newton algorithm and neither does its pseudo-inverse."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "from menpofit.transform import (OrthoMDTransform, \n",
      "                                DifferentiablePiecewiseAffine, \n",
      "                                DifferentiableAlignmentSimilarity)\n",
      "\n",
      "# choose shape parameter\n",
      "param_ind = 0\n",
      "\n",
      "# initialize residual derivative and counter\n",
      "dr_db0 = 0\n",
      "count = 0\n",
      "\n",
      "for i in images[:200]:\n",
      "    # build warp transform\n",
      "    W = OrthoMDTransform(shape_model, DifferentiablePiecewiseAffine,\n",
      "                         DifferentiableAlignmentSimilarity, \n",
      "                         source=reference_frame.landmarks['source'].lms)\n",
      "    # extract image ground truth shape\n",
      "    shape = i.landmarks['ibug_face_66'].lms\n",
      "    # set warp tranform target to the previous shape\n",
      "    W.set_target(shape)\n",
      "    # save the otimal shape parameters for the ground truth shape\n",
      "    b_star = W.as_vector()\n",
      "    # warp image to the reference frame\n",
      "    IWxp = i.warp_to_mask(reference_frame.mask, W)\n",
      "    # compute residual\n",
      "    r_star = IWxp.as_vector() - appearance_model.mean().as_vector()\n",
      "    for delta in np.arange(-10, 10, 1):\n",
      "        if delta != 0:\n",
      "            # perturb shape parameter\n",
      "            b_tilde = b_star.copy()\n",
      "            b_tilde[param_ind] = b_tilde[param_ind] + delta\n",
      "            # set transform to the pertubed position\n",
      "            W.from_vector_inplace(b_tilde)\n",
      "            # warp image to the reference frame using perturbed transform\n",
      "            IWxp = i.warp_to_mask(reference_frame.mask, W)\n",
      "            # compute perturbed residual\n",
      "            r_tilde = IWxp.as_vector() - appearance_model.mean().as_vector()\n",
      "            # add to approximation\n",
      "            dr_db0 += (r_tilde - r_star) / delta\n",
      "            count += 1\n",
      "\n",
      "# normalize by the total number of iterations\n",
      "dr_db0 = dr_db0 / count"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 105
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reference_frame.from_vector(dr_db0).view()"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 106,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 106,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "- **Analytical derivation**:\n",
      "\n",
      "The analytical derivation is can be obtained by directly applying the chain rule:\n",
      "\n",
      "$$ \\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{b}} = \\left( \\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{c}}, \\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{p}} \\right) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 108
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$ \\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{c}} = \\frac{\\partial \\left( \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right)}{\\partial\\mathbf{c}} = \\mathbf{A}$$\n",
      "\n",
      "Note that the derivative of the residual with respect to appearance parameters is **fixed**, i.e. it does not depend on the current shape or appearance parameters. In fact, it is equal to appearance model bases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 109
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{p}} = \\frac{\\partial \\left( \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right)}{\\partial\\mathbf{p}} = \\nabla I(\\mathcal{W}(\\mathbf{x};\\mathbf{p})) \\frac{\\partial \\mathcal{W}}{\\partial \\mathbf{p}}$$\n",
      "\n",
      "On the contrary, the derivative of the residual with respect to shape parameters does depend on the current shape parameters and will have to be estimated at every iteration of the algorithm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.feature import gradient\n",
      "\n",
      "# reset warp tranform to img initial shape\n",
      "W.set_target(initial_shape)\n",
      "\n",
      "# warp image to reference frame\n",
      "IWxp = img.warp_to_mask(reference_frame.mask, W)\n",
      "# compute gradient of warped image\n",
      "VI_image = gradient(IWxp)\n",
      "VI_image.set_boundary_pixels()\n",
      "# reshape gradient\n",
      "VI = VI_image.as_vector().reshape((2, -1))"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 110
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "VI_image.view();"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 111
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the warp derivative with respect to shape parameters\n",
      "dW_dp = W.d_dp(reference_frame.mask.true_indices())\n",
      "dW_dp = np.rollaxis(dW_dp, -1)\n",
      "\n",
      "# make them menpo images for visualization\n",
      "template = reference_frame.copy()\n",
      "template.pixels = np.concatenate((template.pixels, template.pixels), axis=0)\n",
      "dW_dp_image = [template.from_vector(dW_dp[:, :, p].flatten()) \n",
      "               for p in xrange(W.n_parameters)]"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 112
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visualize_images(dW_dp_image)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 113
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute steepest descent images\n",
      "sdi = 0\n",
      "a = VI[..., None] * dW_dp\n",
      "for d in a:\n",
      "    sdi += d\n",
      "# make them menpo images for visualization\n",
      "sdi_image = [reference_frame.from_vector(sdi[:, p].flatten()) \n",
      "             for p in xrange(W.n_parameters)]"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 114
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visualize_images(sdi_image)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 115
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 116,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Iain Matthews and Simon Baker were the first to make use of the analytical computation of the residual derivative. A very detailed explanation of all the terms involving the derivation of the derivative is given in their paper (Matthews and Baker, 2003)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 116,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The Gauss-Newton algorithm we just described is known as the **Simultaneous Forward Additive (SFA)** algorithm. It is just one algorithm of a whole family of Gauss-Newton algorithm for solving the AAM fitting problem using the analytical derivation of the residual derivative.\n",
      "\n",
      "Another algorithm of the same family is:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 118
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The **Project Out Inverse Compositional (PIC)** algorithm:\n",
      "\n",
      "This algorithm divides the original cost function in two different terms: \n",
      "\n",
      "- One that acts on the linear subspace spanned by the appearance bases. \n",
      "- One that acts on its **orthogonal complement**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 119
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right\\|^2 =  \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right\\|^2_{\\mathbf{A}^\\perp} + \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right\\|^2_{\\mathbf{A}} $$\n",
      "\n",
      "$$\\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right\\|^2 =  \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} \\right\\|^2_{\\mathbf{A}^\\perp} + \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} - \\mathbf{A}\\mathbf{c} \\right\\|^2_{\\mathbf{A}} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 120
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "How can we compute the orthogonal complement to the appearance subspace?    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 121
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\\mathbf{A}^\\perp = \\mathbf{I} - \\mathbf{A}\\mathbf{A}^T$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 122
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "A quick one dimensional example proving that the above is true:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "a = np.array([1, 1])\n",
      "a = a / np.sqrt(a.T.dot(a))\n",
      "\n",
      "r = np.array([0.3, 0.7])\n",
      "\n",
      "a_perp = np.eye(2) - a.dot(a.T)\n",
      "\n",
      "r_proj = a.dot(a.T.dot(r))\n",
      "r_perp = r - r_proj\n",
      "\n",
      "plt.figure()\n",
      "ax = plt.gca()\n",
      "ax.quiver([0, 0, 0, r_proj[0]], [0, 0, 0, r_proj[1]], \n",
      "          [a[0], r[0], r_proj[0], r_perp[0]],\n",
      "          [a[1], r[1], r_proj[1], r_perp[1]], \n",
      "          angles='xy', scale_units='xy', scale=1,\n",
      "          color=['k', 'r', 'g', 'b'])\n",
      "ax.set_xlim([0, 1])\n",
      "ax.set_ylim([0, 1])\n",
      "ax.set_aspect('equal')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 122
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 124
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The optimal value for the shape parameters can be obtained by solving the following optimization problem:\n",
      "    \n",
      "$$\\mathbf{p}_o = \\underset{\\mathbf{p}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}} \\right\\|^2_{(\\mathbf{I} -\\mathbf{A}\\mathbf{A}^T)}$$ \n",
      "\n",
      "$$\\mathbf{p}_o = \\underset{\\mathbf{p}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\mathbf{r}^T(\\mathbf{I} -\\mathbf{A}\\mathbf{A}^T)\\mathbf{r}$$  \n",
      "\n",
      "Note that working on the orthogonal complement of the appearance bases accounts for the **Project Out** in the algorithm's name. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 125
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The **Inverse** bit comes from the fact that the algorithm switches the roles of the image and the template by introducing an incremental warp onto the the model's part:\n",
      "\n",
      "$$\\mathbf{p}_o = \\underset{\\mathbf{p}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\left\\| \\mathbf{i}[\\mathbf{p}] -  \\bar{\\mathbf{a}}[\\Delta\\mathbf{p}] \\right\\|^2_{(\\mathbf{I} -\\mathbf{A}\\mathbf{A}^T)} $$  \n",
      "\n",
      "Similarly as before, this new non-linear squares problem can be solve by using the Gauss-Newton algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 126
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In this case the, the first order Taylor expansion of the residual leads to:\n",
      "\n",
      "$$ \\mathbf{r}(\\mathbf{p} \\circ \\Delta \\mathbf{p}^{-1}) \\approx \\mathbf{r}(\\mathbf{p}) + \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{p}} \\Delta \\mathbf{p} $$\n",
      "\n",
      "where:\n",
      "\n",
      "$$\\frac{\\partial\\mathbf{r}}{\\partial \\mathbf{p}} = - \\nabla \\bar{A}(\\mathbf{x}) \\frac{\\partial\\mathcal{W}}{\\partial\\mathbf{p}} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 127
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Substituing back onto the cost function we arrive to very similar expression as before:\n",
      "\n",
      "$$\\Delta \\mathbf{p}_o = \\underset{\\Delta\\mathbf{p}}{\\mathrm{arg\\,min\\;}} \\, \\mathcal{f}(\\Delta \\mathbf{p}) = \\underset{\\Delta\\mathbf{p}}{\\mathrm{arg\\,min\\;}} \\, \\frac{1}{2} \\left\\| \\mathbf{r}(\\mathbf{p}) + \\frac{\\partial \\mathbf{r}^T}{\\partial \\mathbf{p}} \\Delta \\mathbf{p} \\right\\|^2 $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 128
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "And the solution for the increments on the shape parameters is given by the now familiar expression:\n",
      "\n",
      "$$\\Delta \\mathbf{p}_o = \\left(\\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{p}}^T \\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{p}}\\right)^{-1} \\frac{\\partial\\mathbf{r}}{\\partial\\mathbf{p}} \\mathbf{r}(\\mathbf{p}) $$\n",
      "\n",
      "$$\\Delta \\mathbf{p}_o = \\mathbf{R} \\mathbf{r}(\\mathbf{p}) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 129
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "As noted above, the previous increments on the shape parameters are placed on the model's side. \n",
      "\n",
      "This effectively means that the problem that we just solved was that of finding the shape parameters that best deform the **model** so that the difference between the warped image and the model was minimized.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 130
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Therefore, we cannot simply add these shape parameters increments to the current ones using and additive update rule.\n",
      "\n",
      "Instead, what we need to do is to **invert** the incremental warp and **compose** it to current warp. Giving rise to following updating rule:\n",
      "\n",
      "$$\\mathcal{W}(\\mathbf{x}; \\mathbf{p}) \\leftarrow \\mathcal{W}(\\mathbf{x}; \\mathbf{p}) \\circ \\mathcal{W}(\\mathbf{x}; \\Delta \\mathbf{p})^{-1}$$\n",
      "\n",
      "or slightly abusing the notation:\n",
      "\n",
      "$$\\mathbf{p} \\leftarrow \\mathbf{p} \\circ \\Delta \\mathbf{p}^{-1}$$\n",
      "\n",
      "And yes, as you have probably guessed by now, this accounts for the **Compositional** in the algorithm's name."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 131
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This algorithm has two main **advantages** with respect to the previous *SFA* algorithm we derived earlier: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 132
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The appearance parameters have being completely **removed** from the optimization problem. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 133,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- The derivative of the residual with respect to the shape parameters is **constant** and, consequently, so is its pseudo-inverse which can now be completely **pre-computed**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 133,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "There are at least two other very well-known and widely used Gauss-Newton algorithms for fitting AAMs, i.e.:\n",
      "\n",
      "- **Alternating Inverse Compositional (AIC)** algorithm (Tzimiropoulos et al., 2012)\n",
      "\n",
      "- **Fast Simultaneous Inverse Compositional (Fast-SIC)** algorithm (Papandreou and Maragos, 2008)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 135
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "There derivation is similar to that of the previous *SFA* and *PIC* algorithms but, unfortunately, I did not have enough time to prepare a full derivation of these algorithms."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 136,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can still quickly do it on the whiteboard if you are interested... :-)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 136,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "OK, **maths are over**!!!\n",
      "\n",
      "Let's see how each one of these algorithms perform!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 138
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We will start by loading some test images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.landmark import labeller, ibug_face_66\n",
      "\n",
      "test_images = []\n",
      "for i  in mio.import_images('/Users/joan/PhD/DataBases/faces/lfpw/testset/', \n",
      "                            max_images=10, verbose=True):\n",
      "    \n",
      "    i.crop_to_landmarks_proportion_inplace(0.5)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200)\n",
      "    labeller(i, 'PTS', ibug_face_66)\n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='luminosity')\n",
      "    \n",
      "    test_images.append(i)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 139
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 140
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Now let's load an AAM and fit it to the previous images using the following algorithms:\n",
      "\n",
      "- **Project Out Inverse Algorithm (PIC)**\n",
      "- **Alternating Inverse Algorithm (AIC)**\n",
      "- **Fast Simultaneous Inverse Algorithm (Fast-SIC)**.\n",
      "\n",
      "Sadly numerical approximation algorithms for fitting AAMs have not been implemented yet in menpo :-( so the list of algorithms is limited to those using analytical derivations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load a pre-trained AAM\n",
      "aam = pickle_load('/Users/joan/PhD/Models/gaam_int.menpo')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 141
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alabortijcv2015.aam import StandardAAMFitter\n",
      "from alabortijcv2015.aam.algorithm import PIC, AIC, SIC \n",
      "\n",
      "# build aam fitter with PIC algorithm\n",
      "pic_fitter = StandardAAMFitter(aam, algorithm_cls=PIC, n_shape=10, n_appearance=100)\n",
      "# build aam fitter with AIC algorithm\n",
      "aic_fitter = StandardAAMFitter(aam, algorithm_cls=AIC, n_shape=10, n_appearance=100)\n",
      "# build aam fitter with Fast-SIC algorithm\n",
      "sic_fitter = StandardAAMFitter(aam, algorithm_cls=SIC, n_shape=10, n_appearance=100)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 142
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intialize list of fitter results\n",
      "pic_fitter_results = []\n",
      "aic_fitter_results = []\n",
      "sic_fitter_results = []\n",
      "\n",
      "np.random.seed(1)\n",
      "\n",
      "for j, i in enumerate(test_images):  \n",
      "    # get the ground truth landmark for the test image\n",
      "    gt_s = i.landmarks['PTS'].lms\n",
      "    # noisy align the model's mean shape to them\n",
      "    s = pic_fitter.perturb_shape(gt_s, noise_std=0.02)\n",
      "    \n",
      "    # fit with PIC\n",
      "    pic_fr = pic_fitter.fit(i, s, gt_shape=gt_s, max_iters=20)\n",
      "    # fit with AIC\n",
      "    aic_fr = aic_fitter.fit(i, s, gt_shape=gt_s, max_iters=20)\n",
      "    # fit with Fast-SIC\n",
      "    sic_fr = sic_fitter.fit(i, s, gt_shape=gt_s, max_iters=20)\n",
      "    \n",
      "    # this nonsense is due to a bug in my code!!!\n",
      "    pic_fr.downscale = 0.5\n",
      "    aic_fr.downscale = 0.5\n",
      "    sic_fr.downscale = 0.5\n",
      "    \n",
      "    # add fitter results to their respective list\n",
      "    pic_fitter_results.append(pic_fr)\n",
      "    aic_fitter_results.append(aic_fr)\n",
      "    sic_fitter_results.append(sic_fr)\n",
      "    \n",
      "    # print the error per fitting\n",
      "    print 'Image: ', j\n",
      "    print 'PIC:' \n",
      "    print pic_fr\n",
      "    print 'AIC'\n",
      "    print aic_fr\n",
      "    print 'SIC'\n",
      "    print sic_fr"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 143
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 144
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can also check the results visually:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.visualize import visualize_fitting_results\n",
      "\n",
      "visualize_fitting_results(pic_fitter_results)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 145
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.visualize import visualize_fitting_results\n",
      "\n",
      "visualize_fitting_results(aic_fitter_results)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 146
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofit.visualize import visualize_fitting_results\n",
      "\n",
      "visualize_fitting_results(sic_fitter_results)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 147,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 147,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Finally, let us also quickly compare the speed of each algorithm:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit pic_fitter.fit(i, s, gt_shape=gt_s, max_iters=20)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 149
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit aic_fitter.fit(i, s, gt_shape=gt_s, max_iters=20)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 150
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sic_fitter.fit(i, s, gt_shape=gt_s, max_iters=20)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 151,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 151,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Things to take with you from this second part:\n",
      "\n",
      "- AAM fitting is defined as a **non-linear squares** problem.\n",
      "\n",
      "- The **Gauss-Newton** algorithm can be used to solve AAM fitting.\n",
      "  - **Numerical** approximation.\n",
      "  - **Analytical** derivation.\n",
      "\n",
      "- Analytical algorithms are defined by:\n",
      "  - The way in which they handle the appearance parameters:\n",
      "   - **Project out**.\n",
      "   - **Alternating**.\n",
      "   - **Simultaneous**.\n",
      "  - The roles that the input image and the appearance model problem play in the optimization:\n",
      "   - **Forward**.\n",
      "   - **Inverse**.\n",
      "  - The update rule:\n",
      "   - **Additive**.\n",
      "   - **Compositional**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 153
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 153
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Part 3: Feature-based Active Appearance Models\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 153,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Part 4: Supervised Descent Method\n",
      "---"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}