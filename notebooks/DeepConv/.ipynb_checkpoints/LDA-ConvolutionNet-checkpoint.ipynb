{
 "metadata": {
  "name": "",
  "signature": "sha256:46618fee2c80ae703616cdbaf381269d1d5bea266d1b0f9a6a1796a964659b5f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pylab as plt\n",
      "import matplotlib.cm as cm\n",
      "import numpy as np\n",
      "\n",
      "import menpo.io as mio\n",
      "from menpo.image import Image\n",
      "from menpo.model import PCAModel\n",
      "from menpo.fitmultilevel.functions import mean_pointcloud, extract_local_patches_fast\n",
      "from menpo.visualize.widgets import browse_images\n",
      "    \n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linear_discriminant_decomposition(Xs, whiten=False, center=True,\n",
      "                                      bias=False, inplace=False):\n",
      "    r\"\"\"\n",
      "    \"\"\"\n",
      "    \n",
      "    C = len(Xs)\n",
      "    \n",
      "    mus = [np.mean(X, axis=0) for X in Xs]\n",
      "    T = np.mean(np.asarray(mus), axis=0)\n",
      "    \n",
      "    Sigmas = []\n",
      "    Omegas = []\n",
      "    for (X, mu) in zip(Xs, mus):\n",
      "        n_samples, n_features = X.shape\n",
      "        \n",
      "        if bias:\n",
      "            N = n_samples\n",
      "        else:\n",
      "            N = n_samples - 1.0\n",
      "        \n",
      "        X = X - mu\n",
      "        Sigmas.append(np.dot(X.T, X) / N)\n",
      "        \n",
      "        mu = mu - T\n",
      "        Omegas.append(np.dot(mu[:, None], mu[None, :]) / C)\n",
      "        \n",
      "    S = 0\n",
      "    for Sig in Sigmas:\n",
      "        S += Sig\n",
      "        \n",
      "    O = 0\n",
      "    for Ome in Omegas:\n",
      "        O += Ome\n",
      "        \n",
      "    C = np.linalg.solve(S, O)\n",
      "    \n",
      "    from menpo.math.decomposition import eigenvalue_decomposition\n",
      "    \n",
      "    eigenvectors, eigenvalues = eigenvalue_decomposition(C)\n",
      "        \n",
      "    return eigenvectors, eigenvalues"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images = []\n",
      "for i in mio.import_images('/data/PhD/DataBases/lfpw/trainset/*', verbose=True, max_images=100):\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5)\n",
      "    if i.n_channels > 1:\n",
      "        i = i.as_greyscale()\n",
      "    images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "browse_images(images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rescaled_images = [i.rescale_landmarks_to_diagonal_range(256) for i in images] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "browse_images(rescaled_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img_size = (150, 150)\n",
      "resized_images = [i.resize(img_size) for i in images] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "browse_images(resized_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_shape = (12, 12)\n",
      "lim = patch_shape[0] / 2\n",
      "\n",
      "n_pcs = 50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = resized_images[1].copy()\n",
      "img.build_mask_around_landmarks(patch_shape)\n",
      "img.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del images, rescaled_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1st Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list = []\n",
      "for i in resized_images:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_classes = []\n",
      "for j in range(patches.shape[0]):\n",
      "    patch_images = []\n",
      "    for patches in patches_list:\n",
      "        patch_img = patches[j, :, :, 0]\n",
      "        patch_images.append(patch_img)\n",
      "    patch_classes.append(np.reshape(np.asarray(patch_images), (-1, np.prod(patch_shape))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvectors, eigenvalues= linear_discriminant_decomposition(patch_classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.reshape(eigenvectors[:, 0], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 1], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 2], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 3], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 4], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 5], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 6], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 7], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 8], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(eigenvectors[:, 9], patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = np.zeros((256, 256))\n",
      "#X[:lim, :lim] = patch_pca.mean.pixels[:lim, :lim, 0]\n",
      "#X[-lim:, :lim] = patch_pca.mean.pixels[lim:, :lim, 0]\n",
      "#X[:lim, -lim:] = patch_pca.mean.pixels[:lim, lim:, 0]\n",
      "#X[-lim:, -lim:] = patch_pca.mean.pixels[lim:, lim:, 0]\n",
      "#pc = [X] \n",
      "\n",
      "pc = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size)\n",
      "    X[:lim, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, :lim]\n",
      "    X[-lim:, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, :lim]\n",
      "    X[:lim, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, lim:]\n",
      "    X[-lim:, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, lim:]\n",
      "    pc.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H = []\n",
      "S = 0\n",
      "for f in pc[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H.append(fft_filt)\n",
      "    S += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 0\n",
      "filtered_img_fft = np.fft.fft2(resized_images[index].pixels[..., -1])  * S\n",
      "response_map = np.fft.ifft2(filtered_img_fft)\n",
      "Image(np.abs(response_map)).view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.abs(H[0]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[1]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[2]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[3]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[4]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[5]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[6]), cmap=cm.Greys_r)\n",
      "\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(S), cmap=cm.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resized_images_fft = [np.fft.fft2(i.pixels[..., -1]) for i in resized_images]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps = []\n",
      "for i_fft, i in zip(resized_images_fft, resized_images):\n",
      "    for h in H:\n",
      "        filtered_img_fft = i_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps[0].pixels)).view()\n",
      "Image(np.abs(response_maps[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps[9].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2nd Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list2 = []\n",
      "for i in response_maps:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape, dtype=np.complex)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list2.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_classes2 = []\n",
      "for j in range(patches.shape[0]):\n",
      "    patch_images = []\n",
      "    for patches in patches_list2:\n",
      "        patch_img = patches[j, :, :, 0]\n",
      "        patch_images.append(patch_img)\n",
      "    patch_classes2.append(np.reshape(np.asarray(patch_images), (-1, np.prod(patch_shape))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvectors, eigenvalues= linear_discriminant_decomposition(patch_classes2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 0]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 1]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 2]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 3]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 4]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 5]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 6]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 7]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 8]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 9]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = np.zeros((256, 256))\n",
      "#X[:lim, :lim] = patch_pca.mean.pixels[:lim, :lim, 0]\n",
      "#X[-lim:, :lim] = patch_pca.mean.pixels[lim:, :lim, 0]\n",
      "#X[:lim, -lim:] = patch_pca.mean.pixels[:lim, lim:, 0]\n",
      "#X[-lim:, -lim:] = patch_pca.mean.pixels[lim:, lim:, 0]\n",
      "#pc = [X] \n",
      "\n",
      "pc2 = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size, dtype=np.complex)\n",
      "    X[:lim, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, :lim]\n",
      "    X[-lim:, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, :lim]\n",
      "    X[:lim, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, lim:]\n",
      "    X[-lim:, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, lim:]\n",
      "    pc2.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H2 = []\n",
      "S2 = 0\n",
      "for f in pc2[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H2.append(fft_filt)\n",
      "    S2 += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 0\n",
      "rm = resized_images[index].pixels[..., -1]\n",
      "Image(np.abs(rm)).view_new()\n",
      "\n",
      "\n",
      "rm_ftt = np.fft.fft2(rm) * (S * S2)\n",
      "rm2 = np.fft.ifft2(rm_ftt)\n",
      "Image(np.abs(rm2)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps_fft = [np.fft.fft2(i.pixels[..., -1]) for i in response_maps]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps2 = []\n",
      "for rm_fft, i in zip(response_maps_fft, resized_images):\n",
      "    for h in H2:\n",
      "        filtered_img_fft = rm_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps2.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps2[0].pixels)).view()\n",
      "Image(np.abs(response_maps2[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[9].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[10].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3rd Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list3 = []\n",
      "for i in response_maps2:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape, dtype=np.complex)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list3.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_classes3 = []\n",
      "for j in range(patches.shape[0]):\n",
      "    patch_images = []\n",
      "    for patches in patches_list3:\n",
      "        patch_img = patches[j, :, :, 0]\n",
      "        patch_images.append(patch_img)\n",
      "    patch_classes3.append(np.reshape(np.asarray(patch_images), (-1, np.prod(patch_shape))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvectors, eigenvalues= linear_discriminant_decomposition(patch_classes3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 0]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 1]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 2]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 3]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 4]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 5]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 6]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 7]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 8]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 9]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc3 = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size, dtype=np.complex)\n",
      "    X[:lim, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, :lim]\n",
      "    X[-lim:, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, :lim]\n",
      "    X[:lim, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, lim:]\n",
      "    X[-lim:, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, lim:]\n",
      "    pc3.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H3 = []\n",
      "S3 = 0\n",
      "for f in pc3[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H3.append(fft_filt)\n",
      "    S3 += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 1\n",
      "rm = resized_images[index].pixels[..., -1]\n",
      "Image(np.abs(rm)).view_new()\n",
      "\n",
      "\n",
      "rm_ftt = np.fft.fft2(rm) * S * S2 * S3\n",
      "rm2 = np.fft.ifft2(rm_ftt)\n",
      "Image(np.abs(rm2)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps_fft2 = [np.fft.fft2(i.pixels[..., -1]) for i in response_maps2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps3 = []\n",
      "for rm_fft, i in zip(response_maps_fft2, resized_images):\n",
      "    for h in H3:\n",
      "        filtered_img_fft = rm_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps3.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps3[0].pixels)).view()\n",
      "Image(np.abs(response_maps3[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[9].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[10].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4th Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list4 = []\n",
      "for i in response_maps3:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape, dtype=np.complex)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list4.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_classes4 = []\n",
      "for j in range(patches.shape[0]):\n",
      "    patch_images = []\n",
      "    for patches in patches_list4:\n",
      "        patch_img = patches[j, :, :, 0]\n",
      "        patch_images.append(patch_img)\n",
      "    patch_classes4.append(np.reshape(np.asarray(patch_images), (-1, np.prod(patch_shape))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvectors, eigenvalues= linear_discriminant_decomposition(patch_classes4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 0]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 1]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 2]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 3]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 4]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 5]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 6]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 7]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 8]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")\n",
      "plt.figure()\n",
      "plt.imshow(np.reshape(np.abs(eigenvectors[:, 9]), patch_shape),  cmap=cm.Greys_r, interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc4 = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size, dtype=np.complex)\n",
      "    X[:lim, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, :lim]\n",
      "    X[-lim:, :lim] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, :lim]\n",
      "    X[:lim, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[:lim, lim:]\n",
      "    X[-lim:, -lim:] = np.reshape(eigenvectors[:, j], patch_shape)[lim:, lim:]\n",
      "    pc4.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H4 = []\n",
      "S4 = 0\n",
      "for f in pc4[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H4.append(fft_filt)\n",
      "    S4 += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 1\n",
      "rm = resized_images[index].pixels[..., -1]\n",
      "Image(np.abs(rm)).view_new()\n",
      "\n",
      "\n",
      "rm_ftt = np.fft.fft2(rm) * S * S2 * S3 * S4\n",
      "rm2 = np.fft.ifft2(rm_ftt)\n",
      "Image(np.abs(rm2)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps_fft3 = [np.fft.fft2(i.pixels[..., -1]) for i in response_maps3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps4 = []\n",
      "for rm_fft, i in zip(response_maps_fft3, resized_images):\n",
      "    for h in H4:\n",
      "        filtered_img_fft = rm_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps4.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps4[0].pixels)).view()\n",
      "Image(np.abs(response_maps4[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[9].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[10].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Alignment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S = 0\n",
      "for h in H2:\n",
      "    S += np.dot(np.conjugate(h.T), h) \n",
      "    \n",
      "SS = 0\n",
      "for h2 in H2:\n",
      "    SS += np.dot(np.conjugate(h2.T), np.dot(S, h2)) \n",
      "    \n",
      "SSS = 0\n",
      "for h3 in H3:\n",
      "     SSS += np.dot(np.conjugate(h3.T), np.dot(SS, h3)) \n",
      "        \n",
      "SSSS = 0\n",
      "for h4 in H4:\n",
      "     SSSS += np.dot(np.conjugate(h4.T), np.dot(SSS, h4)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "np.set_printoptions(linewidth=500, precision=3)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import menpo.io as mio\n",
      "\n",
      "takeo = mio.import_builtin_asset('breakingbad.jpg')\n",
      "takeo = takeo.rescale(0.5)\n",
      "takeo.view();\n",
      "\n",
      "takeo = takeo.as_greyscale()\n",
      "print(takeo.n_channels)\n",
      "print(takeo.pixels.shape)\n",
      "takeo.view_new();\n",
      "\n",
      "from menpo.transform import AlignmentAffine, Affine\n",
      "from menpo.image import BooleanImage\n",
      "\n",
      "target_params = np.array([0.2, 0.1, 0.1, -0.2, 30, 605])\n",
      "target_transform = Affine.identity(2).from_vector(target_params)\n",
      "# printing an affine transform tells us what it does\n",
      "print(target_transform)\n",
      "\n",
      "# make a blank (default filled with 0's) greyscale (default: 1 channel) image to guide the warp\n",
      "template = BooleanImage.blank((150, 150))\n",
      "\n",
      "target = takeo.warp_to(template, target_transform)\n",
      "target.view_new();\n",
      "\n",
      "from menpo.fit.lucaskanade.image import ImageInverseCompositional, ImageForwardAdditive, ImageForwardCompositional\n",
      "from copy import deepcopy\n",
      "\n",
      "# Create the initial transform as an alignment transform\n",
      "# so that we can get more interesting fitting information,\n",
      "# since we then know the ground truth!\n",
      "initial_params = np.array([0., 0, 0, 0, 30, 600])\n",
      "inital_transform = Affine.identity(2).from_vector(initial_params)\n",
      "\n",
      "from menpo.fit.lucaskanade.residual import LSIntensity, ECC, FourierSSD, GaborFourier, GradientCorrelation\n",
      "\n",
      "#residual = GaborFourier(SS.shape)\n",
      "residual = FourierSSD(SSSS)\n",
      "#residual = LSIntensity()\n",
      "#residual = GradientCorrelation()\n",
      "\n",
      "from menpo.shape import PointCloud\n",
      "\n",
      "# Create the identity 'box' -> representing the area\n",
      "# that the target image was warped into\n",
      "corners = target.shape\n",
      "identity_box = PointCloud(np.array([[0,          0],\n",
      "                                    [corners[0], 0],\n",
      "                                    [corners[0], corners[1]],\n",
      "                                    [0,          corners[1]]]))\n",
      "\n",
      "# This is the initial 'box' that we are warping into\n",
      "initial_box = inital_transform.apply(identity_box)\n",
      "inital_transform = AlignmentAffine(identity_box, initial_box)\n",
      "\n",
      "inv_comp = ImageInverseCompositional(target, residual, deepcopy(inital_transform))\n",
      "for_add = ImageForwardAdditive(target, residual, deepcopy(inital_transform))\n",
      "for_comp = ImageForwardCompositional(target, residual, deepcopy(inital_transform))\n",
      "\n",
      "%matplotlib inline\n",
      "# Get Inverse Compositional optimum transform and plot\n",
      "inv_comp_fitting = inv_comp.fit(takeo, initial_params)\n",
      "inv_comp_res = takeo.warp_to(template, inv_comp_fitting.final_transform)\n",
      "plt.subplot(141)\n",
      "inv_comp_res.view();\n",
      "\n",
      "# Get Forward Compositional optimum transform and plot\n",
      "for_comp_fitting = for_comp.fit(takeo, initial_params)\n",
      "for_comp_res = takeo.warp_to(template, for_comp_fitting.final_transform)\n",
      "plt.subplot(142)\n",
      "for_comp_res.view();\n",
      "\n",
      "# Plot target image we were warping to\n",
      "plt.subplot(144)\n",
      "target.view();\n",
      "\n",
      "# Set Figure to be larger\n",
      "plt.gcf().set_size_inches(12.0, 5.0)\n",
      "\n",
      "# Create the target 'box' that the target was warped into\n",
      "target_box = target_transform.apply(identity_box)\n",
      "\n",
      "# Setup the fitting objects so we can generate useful results\n",
      "inv_comp_fitting.error_type = 'rmse'\n",
      "inv_comp_fitting.gt_shape = target_box\n",
      "for_comp_fitting.error_type = 'rmse'\n",
      "for_comp_fitting.gt_shape = target_box\n",
      "\n",
      "print('Inverse compositional RMS error: {0}'.format(inv_comp_fitting.final_error()))\n",
      "print('Forward compositional RMS error: {0}'.format(for_comp_fitting.final_error()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for_comp_fitting.final_image.landmarks['initial'].view()\n",
      "for_comp_fitting.final_image.landmarks['final'].view_new()\n",
      "for_comp_fitting.final_image.landmarks['ground'].view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}