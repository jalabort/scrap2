{
 "metadata": {
  "name": "",
  "signature": "sha256:ed3db63625f908a907db3d29d444f0ef0f42c0cf880509f5bf55496a7bd08ae9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pylab as plt\n",
      "import matplotlib.cm as cm\n",
      "import numpy as np\n",
      "\n",
      "import menpo.io as mio\n",
      "from menpo.image import Image\n",
      "from menpo.model import PCAModel\n",
      "from menpo.fitmultilevel.functions import mean_pointcloud, extract_local_patches_fast\n",
      "from menpo.visualize.widgets import browse_images\n",
      "    \n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images = []\n",
      "for i in mio.import_images('/data/PhD/DataBases/lfpw/trainset/*', verbose=True, max_images=100):\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5)\n",
      "    if i.n_channels > 1:\n",
      "        i = i.as_greyscale()\n",
      "    images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "browse_images(images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rescaled_images = [i.rescale_landmarks_to_diagonal_range(256) for i in images] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "browse_images(rescaled_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img_size = (100, 100)\n",
      "resized_images = [i.resize(img_size) for i in images] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "browse_images(resized_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_shape = (12, 12)\n",
      "lim = patch_shape[0] / 2\n",
      "\n",
      "n_pcs = 50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = resized_images[1].copy()\n",
      "img.build_mask_around_landmarks(patch_shape)\n",
      "img.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del images, rescaled_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1st Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list = []\n",
      "for i in resized_images:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_images = []\n",
      "for patches in patches_list:\n",
      "    for patch in patches:\n",
      "        patch_img = Image(patch[:, :, 0])\n",
      "        patch_images.append(patch_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca = PCAModel(patch_images, center=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca.mean.view(interpolation=\"nearest\")\n",
      "patch_pca.component(1).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(2).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(3).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(4).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(5).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(6).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(7).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(8).view_new(interpolation=\"nearest\")\n",
      "patch_pca.component(9).view_new(interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = np.zeros((256, 256))\n",
      "#X[:lim, :lim] = patch_pca.mean.pixels[:lim, :lim, 0]\n",
      "#X[-lim:, :lim] = patch_pca.mean.pixels[lim:, :lim, 0]\n",
      "#X[:lim, -lim:] = patch_pca.mean.pixels[:lim, lim:, 0]\n",
      "#X[-lim:, -lim:] = patch_pca.mean.pixels[lim:, lim:, 0]\n",
      "#pc = [X] \n",
      "\n",
      "pc = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size)\n",
      "    X[:lim, :lim] = patch_pca.component(j).pixels[:lim, :lim, 0]\n",
      "    X[-lim:, :lim] = patch_pca.component(j).pixels[lim:, :lim, 0]\n",
      "    X[:lim, -lim:] = patch_pca.component(j).pixels[:lim, lim:, 0]\n",
      "    X[-lim:, -lim:] = patch_pca.component(j).pixels[lim:, lim:, 0]\n",
      "    pc.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H = []\n",
      "S = 0\n",
      "for f in pc[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H.append(fft_filt)\n",
      "    S += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 0\n",
      "filtered_img_fft = np.fft.fft2(resized_images[index].pixels[..., -1])  * S\n",
      "response_map = np.fft.ifft2(filtered_img_fft)\n",
      "Image(np.abs(response_map)).view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.abs(H[0]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[1]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[2]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[3]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[4]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[5]), cmap=cm.Greys_r)\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(H[6]), cmap=cm.Greys_r)\n",
      "\n",
      "plt.figure()\n",
      "plt.imshow(np.abs(S), cmap=cm.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resized_images_fft = [np.fft.fft2(i.pixels[..., -1]) for i in resized_images]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps = []\n",
      "for i_fft, i in zip(resized_images_fft, resized_images):\n",
      "    for h in H:\n",
      "        filtered_img_fft = i_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps[0].pixels)).view()\n",
      "Image(np.abs(response_maps[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps[9].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2nd Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list2 = []\n",
      "for i in response_maps:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape, dtype=np.complex)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list2.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_images2 = []\n",
      "for patches in patches_list2:\n",
      "    for patch in patches:\n",
      "        patch_img = Image(patch[:, :, 0])\n",
      "        patch_images2.append(patch_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca2 = PCAModel(patch_images2, center=False, dtype=np.complex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca2.mean.view(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(1).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(2).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(3).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(4).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(5).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(6).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(7).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(8).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca2.component(9).pixels[..., -1])).view_new(interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = np.zeros((256, 256))\n",
      "#X[:lim, :lim] = patch_pca.mean.pixels[:lim, :lim, 0]\n",
      "#X[-lim:, :lim] = patch_pca.mean.pixels[lim:, :lim, 0]\n",
      "#X[:lim, -lim:] = patch_pca.mean.pixels[:lim, lim:, 0]\n",
      "#X[-lim:, -lim:] = patch_pca.mean.pixels[lim:, lim:, 0]\n",
      "#pc = [X] \n",
      "\n",
      "pc2 = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size, dtype=np.complex)\n",
      "    X[:lim, :lim] = patch_pca2.component(j).pixels[:lim, :lim, 0]\n",
      "    X[-lim:, :lim] = patch_pca2.component(j).pixels[lim:, :lim, 0]\n",
      "    X[:lim, -lim:] = patch_pca2.component(j).pixels[:lim, lim:, 0]\n",
      "    X[-lim:, -lim:] = patch_pca2.component(j).pixels[lim:, lim:, 0]\n",
      "    pc2.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H2 = []\n",
      "S2 = 0\n",
      "for f in pc2[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H2.append(fft_filt)\n",
      "    S2 += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 0\n",
      "rm = resized_images[index].pixels[..., -1]\n",
      "Image(np.abs(rm)).view_new()\n",
      "\n",
      "\n",
      "rm_ftt = np.fft.fft2(rm) * (S * S2)\n",
      "rm2 = np.fft.ifft2(rm_ftt)\n",
      "Image(np.abs(rm2)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps_fft = [np.fft.fft2(i.pixels[..., -1]) for i in response_maps]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps2 = []\n",
      "for rm_fft, i in zip(response_maps_fft, resized_images):\n",
      "    for h in H2:\n",
      "        filtered_img_fft = rm_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps2.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps2[0].pixels)).view()\n",
      "Image(np.abs(response_maps2[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[9].pixels)).view_new()\n",
      "Image(np.abs(response_maps2[10].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3rd Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list3 = []\n",
      "for i in response_maps2:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape, dtype=np.complex)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list3.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_images3 = []\n",
      "for patches in patches_list3:\n",
      "    for patch in patches:\n",
      "        patch_img = Image(patch[:, :, 0])\n",
      "        patch_images3.append(patch_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca3 = PCAModel(patch_images3, center=False, dtype=np.complex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca3.mean.view(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(1).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(2).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(3).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(4).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(5).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(6).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(7).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(8).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(9).pixels[..., -1])).view_new(interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = np.zeros((256, 256))\n",
      "#X[:lim, :lim] = patch_pca.mean.pixels[:lim, :lim, 0]\n",
      "#X[-lim:, :lim] = patch_pca.mean.pixels[lim:, :lim, 0]\n",
      "#X[:lim, -lim:] = patch_pca.mean.pixels[:lim, lim:, 0]\n",
      "#X[-lim:, -lim:] = patch_pca.mean.pixels[lim:, lim:, 0]\n",
      "#pc = [X] \n",
      "\n",
      "pc3 = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size, dtype=np.complex)\n",
      "    X[:lim, :lim] = patch_pca3.component(j).pixels[:lim, :lim, 0]\n",
      "    X[-lim:, :lim] = patch_pca3.component(j).pixels[lim:, :lim, 0]\n",
      "    X[:lim, -lim:] = patch_pca3.component(j).pixels[:lim, lim:, 0]\n",
      "    X[-lim:, -lim:] = patch_pca3.component(j).pixels[lim:, lim:, 0]\n",
      "    pc3.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H3 = []\n",
      "S3 = 0\n",
      "for f in pc3[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H3.append(fft_filt)\n",
      "    S3 += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 4\n",
      "rm = resized_images[index].pixels[..., -1]\n",
      "Image(np.abs(rm)).view_new()\n",
      "\n",
      "\n",
      "rm_ftt = np.fft.fft2(rm) * S * S2 * S3\n",
      "rm2 = np.fft.ifft2(rm_ftt)\n",
      "Image(np.abs(rm2)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps_fft2 = [np.fft.fft2(i.pixels[..., -1]) for i in response_maps2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps3 = []\n",
      "for rm_fft, i in zip(response_maps_fft2, resized_images):\n",
      "    for h in H3:\n",
      "        filtered_img_fft = rm_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps3.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps3[0].pixels)).view()\n",
      "Image(np.abs(response_maps3[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[9].pixels)).view_new()\n",
      "Image(np.abs(response_maps3[10].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4th Level\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches_list4 = []\n",
      "for i in response_maps3:\n",
      "    patches = extract_local_patches_fast(i, i.landmarks['PTS'].lms, patch_shape, dtype=np.complex)\n",
      "    m =  patches - np.mean(patches, axis=(1, 2))[:, None, None, :]\n",
      "    patches_list4.append(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_images4 = []\n",
      "for patches in patches_list4:\n",
      "    for patch in patches:\n",
      "        patch_img = Image(patch[:, :, 0])\n",
      "        patch_images4.append(patch_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca4 = PCAModel(patch_images4, center=False, dtype=np.complex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_pca4.mean.view(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(1).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(2).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(3).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(4).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(5).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(6).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(7).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(8).pixels[..., -1])).view_new(interpolation=\"nearest\")\n",
      "Image(np.abs(patch_pca3.component(9).pixels[..., -1])).view_new(interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = np.zeros((256, 256))\n",
      "#X[:lim, :lim] = patch_pca.mean.pixels[:lim, :lim, 0]\n",
      "#X[-lim:, :lim] = patch_pca.mean.pixels[lim:, :lim, 0]\n",
      "#X[:lim, -lim:] = patch_pca.mean.pixels[:lim, lim:, 0]\n",
      "#X[-lim:, -lim:] = patch_pca.mean.pixels[lim:, lim:, 0]\n",
      "#pc = [X] \n",
      "\n",
      "pc4 = []\n",
      "for j in np.arange(n_pcs):\n",
      "    X = np.zeros(img_size, dtype=np.complex)\n",
      "    X[:lim, :lim] = patch_pca4.component(j).pixels[:lim, :lim, 0]\n",
      "    X[-lim:, :lim] = patch_pca4.component(j).pixels[lim:, :lim, 0]\n",
      "    X[:lim, -lim:] = patch_pca4.component(j).pixels[:lim, lim:, 0]\n",
      "    X[-lim:, -lim:] = patch_pca4.component(j).pixels[lim:, lim:, 0]\n",
      "    pc4.append(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H4 = []\n",
      "S4 = 0\n",
      "for f in pc4[:]:\n",
      "    fft_filt = np.fft.fft2(f)\n",
      "    H4.append(fft_filt)\n",
      "    S4 += fft_filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 3\n",
      "rm = resized_images[index].pixels[..., -1]\n",
      "Image(np.abs(rm)).view_new()\n",
      "\n",
      "\n",
      "rm_ftt = np.fft.fft2(rm) * S * S2 * S3 * S4\n",
      "rm2 = np.fft.ifft2(rm_ftt)\n",
      "Image(np.abs(rm2)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps_fft3 = [np.fft.fft2(i.pixels[..., -1]) for i in response_maps3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response_maps4 = []\n",
      "for rm_fft, i in zip(response_maps_fft2, resized_images):\n",
      "    for h in H4:\n",
      "        filtered_img_fft = rm_fft * h\n",
      "        response_map = Image(np.fft.ifft2(filtered_img_fft))\n",
      "        response_map.landmarks = i.landmarks\n",
      "        response_maps4.append(response_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(np.abs(response_maps4[0].pixels)).view()\n",
      "Image(np.abs(response_maps4[1].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[2].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[3].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[4].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[5].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[6].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[7].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[8].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[9].pixels)).view_new()\n",
      "Image(np.abs(response_maps4[10].pixels)).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Alignment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S = 0\n",
      "for h in H2:\n",
      "    S += np.dot(np.conjugate(h.T), h) \n",
      "    \n",
      "SS = 0\n",
      "for h2 in H2:\n",
      "    SS += np.dot(np.conjugate(h2.T), np.dot(S, h2)) \n",
      "    \n",
      "SSS = 0\n",
      "for h3 in H3:\n",
      "     SSS += np.dot(np.conjugate(h3.T), np.dot(SS, h3)) \n",
      "        \n",
      "SSSS = 0\n",
      "for h4 in H4:\n",
      "     SSSS += np.dot(np.conjugate(h4.T), np.dot(SS, h4)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "np.set_printoptions(linewidth=500, precision=3)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import menpo.io as mio\n",
      "\n",
      "takeo = mio.import_builtin_asset('takeo.ppm')\n",
      "takeo.view();\n",
      "\n",
      "takeo = takeo.as_greyscale()\n",
      "print(takeo.n_channels)\n",
      "print(takeo.pixels.shape)\n",
      "takeo.view_new();\n",
      "\n",
      "from menpo.transform import AlignmentAffine, Affine\n",
      "from menpo.image import BooleanImage\n",
      "\n",
      "target_params = np.array([0.3, 0.3, 0.2, -0.2, 70, 30])\n",
      "target_transform = Affine.identity(2).from_vector(target_params)\n",
      "# printing an affine transform tells us what it does\n",
      "print(target_transform)\n",
      "\n",
      "# make a blank (default filled with 0's) greyscale (default: 1 channel) image to guide the warp\n",
      "template = BooleanImage.blank((100, 100))\n",
      "\n",
      "target = takeo.warp_to(template, target_transform)\n",
      "target.view_new();\n",
      "\n",
      "from menpo.fit.lucaskanade.image import ImageInverseCompositional, ImageForwardAdditive, ImageForwardCompositional\n",
      "from copy import deepcopy\n",
      "\n",
      "# Create the initial transform as an alignment transform\n",
      "# so that we can get more interesting fitting information,\n",
      "# since we then know the ground truth!\n",
      "initial_params = np.array([0., 0, 0, 0, 84.5, 44.5])\n",
      "inital_transform = Affine.identity(2).from_vector(initial_params)\n",
      "\n",
      "from menpo.fit.lucaskanade.residual import LSIntensity, ECC, FourierSSD, GaborFourier, GradientCorrelation\n",
      "\n",
      "#residual = GaborFourier(SS.shape)\n",
      "residual = FourierSSD(SSSS)\n",
      "#residual = LSIntensity()\n",
      "#residual = GradientCorrelation()\n",
      "\n",
      "from menpo.shape import PointCloud\n",
      "\n",
      "# Create the identity 'box' -> representing the area\n",
      "# that the target image was warped into\n",
      "corners = target.shape\n",
      "identity_box = PointCloud(np.array([[0,          0],\n",
      "                                    [corners[0], 0],\n",
      "                                    [corners[0], corners[1]],\n",
      "                                    [0,          corners[1]]]))\n",
      "\n",
      "# This is the initial 'box' that we are warping into\n",
      "initial_box = inital_transform.apply(identity_box)\n",
      "inital_transform = AlignmentAffine(identity_box, initial_box)\n",
      "\n",
      "inv_comp = ImageInverseCompositional(target, residual, deepcopy(inital_transform))\n",
      "for_add = ImageForwardAdditive(target, residual, deepcopy(inital_transform))\n",
      "for_comp = ImageForwardCompositional(target, residual, deepcopy(inital_transform))\n",
      "\n",
      "%matplotlib inline\n",
      "# Get Inverse Compositional optimum transform and plot\n",
      "inv_comp_fitting = inv_comp.fit(takeo, initial_params)\n",
      "inv_comp_res = takeo.warp_to(template, inv_comp_fitting.final_transform)\n",
      "plt.subplot(141)\n",
      "inv_comp_res.view();\n",
      "\n",
      "# Get Forward Compositional optimum transform and plot\n",
      "for_comp_fitting = for_comp.fit(takeo, initial_params)\n",
      "for_comp_res = takeo.warp_to(template, for_comp_fitting.final_transform)\n",
      "plt.subplot(142)\n",
      "for_comp_res.view();\n",
      "\n",
      "# Plot target image we were warping to\n",
      "plt.subplot(144)\n",
      "target.view();\n",
      "\n",
      "# Set Figure to be larger\n",
      "plt.gcf().set_size_inches(12.0, 5.0)\n",
      "\n",
      "# Create the target 'box' that the target was warped into\n",
      "target_box = target_transform.apply(identity_box)\n",
      "\n",
      "# Setup the fitting objects so we can generate useful results\n",
      "inv_comp_fitting.error_type = 'rmse'\n",
      "inv_comp_fitting.gt_shape = target_box\n",
      "for_comp_fitting.error_type = 'rmse'\n",
      "for_comp_fitting.gt_shape = target_box\n",
      "\n",
      "print('Inverse compositional RMS error: {0}'.format(inv_comp_fitting.final_error()))\n",
      "print('Forward compositional RMS error: {0}'.format(for_comp_fitting.final_error()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for_comp_fitting.final_image.landmarks['initial'].view()\n",
      "for_comp_fitting.final_image.landmarks['final'].view_new()\n",
      "for_comp_fitting.final_image.landmarks['ground'].view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}