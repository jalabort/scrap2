{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "from functools import partial\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.feature import imgfeature, fast_dsift\n",
    "\n",
    "from menpo.landmark import labeller, ibug_face_68_trimesh\n",
    "from menpo.visualize import visualize_images, print_dynamic, plot_graph\n",
    "from menpo.visualize.viewmatplotlib import sample_colours_from_colourmap\n",
    "\n",
    "from menpofit.result import compute_normalise_point_to_point_error\n",
    "from menpofit.aam import (\n",
    "    HolisticAAM, LucasKanadeAAMFitter, \n",
    "    holistic_sampling_from_scale,  holistic_sampling_from_step)\n",
    "from menpofit.aam.algorithm.lk_alabort_arxiv2015 import (\n",
    "    SSDForwardGaussNewton, \n",
    "    SSDInverseGaussNewton,\n",
    "    SSDAsymmetricGaussNewton,\n",
    "    SSDBidirectionalGaussNewtonCombined,\n",
    "    SSDBidirectionalGaussNewtonSimultaneous,\n",
    "    SSDBidirectionalGaussNewtonAlternated)\n",
    "from menpofit.visualize import visualize_fitting_result, plot_ced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@imgfeature\n",
    "def fast_dsift2(image):\n",
    "    if image.n_channels == 3:\n",
    "        image = image.as_greyscale(mode='average')\n",
    "    return fast_dsift(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aam = mio.import_pickle('/Users/joan/PhD/Results/alabort_aam_2015/aam.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/lfpw/testset/', \n",
    "                           verbose=True, max_images=None):    \n",
    "    i = i.rescale_landmarks_to_diagonal_range(200)\n",
    "    i = i.crop_to_landmarks_proportion(0.5)\n",
    "    labeller(i, 'PTS', ibug_face_68_trimesh)\n",
    "    if i.n_channels == 3:\n",
    "        test_images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit AAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_shape = [3, 12]\n",
    "n_appearance = 0.75\n",
    "l = 0.5\n",
    "max_iters = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampled AAM Fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampling_scales = [0.125, 0.25, 0.5, 1.0]\n",
    "\n",
    "fitters = []\n",
    "for scale in sampling_scales:\n",
    "    \n",
    "    sampling_step_1, _ = holistic_sampling_from_scale(aam.appearance_models[0].mean(), \n",
    "                                                      scale=np.minimum(2 * scale, 1))\n",
    "    sampling_step_2, _ = holistic_sampling_from_scale(aam.appearance_models[1].mean(), scale=scale)\n",
    "    \n",
    "    sampling_step = [sampling_step_1, sampling_step_2]\n",
    "\n",
    "    fitter = LucasKanadeAAMFitter(\n",
    "        aam, \n",
    "        lk_algorithm_cls=partial(SSDBidirectionalGaussNewtonSimultaneous, l=l), \n",
    "        n_shape=n_shape, \n",
    "        n_appearance=n_appearance,\n",
    "        sampling=sampling_step)\n",
    "    \n",
    "    fitters.append(fitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting loop, noise = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitters_results_0 = []\n",
    "for j, image in enumerate(test_images):\n",
    "    \n",
    "    np.random.seed(j)\n",
    "    \n",
    "    gt_shape = image.landmarks['ibug_face_68_trimesh'].lms\n",
    "    initial_shape = fitters[0].noisy_shape_from_shape(gt_shape, noise_percentage=0.0)\n",
    "\n",
    "    for fitter in fitters:\n",
    "        \n",
    "        fr = fitter.fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "        fr.downscale = 0.5\n",
    "        fitters_results_0.append(fr)\n",
    "    \n",
    "        print_dynamic(\n",
    "            'Image: {} - Initial error: {} - Final error: {}'\n",
    "            .format(j, fr.initial_error(), fr.final_error()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting loop, noise = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_fitters = len(fitters)\n",
    "legend_entries = ['ini'] + [str(scale) for scale in sampling_scales]\n",
    "\n",
    "fitters_results_1 = []\n",
    "for j, image in enumerate(test_images):\n",
    "    \n",
    "    np.random.seed(j)\n",
    "    \n",
    "    gt_shape = image.landmarks['ibug_face_68_trimesh'].lms\n",
    "    initial_shape = fitters[0].noisy_shape_from_shape(gt_shape, noise_percentage=0.02)\n",
    "\n",
    "    for fitter in fitters:\n",
    "        \n",
    "        fr = fitter.fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "        fr.downscale = 0.5\n",
    "        fitters_results_1.append(fr)\n",
    "    \n",
    "        print_dynamic(\n",
    "            'Image: {} - Initial error: {} - Final error: {}'\n",
    "            .format(j, fr.initial_error(), fr.final_error()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting loop, noise = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_fitters = len(fitters)\n",
    "legend_entries = ['ini'] + [str(scale) for scale in sampling_scales]\n",
    "\n",
    "fitters_results_2 = []\n",
    "for j, image in enumerate(test_images):\n",
    "    \n",
    "    np.random.seed(j)\n",
    "    \n",
    "    gt_shape = image.landmarks['ibug_face_68_trimesh'].lms\n",
    "    initial_shape = fitters[0].noisy_shape_from_shape(gt_shape, noise_percentage=0.04)\n",
    "\n",
    "    for fitter in fitters:\n",
    "        \n",
    "        fr = fitter.fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "        fr.downscale = 0.5\n",
    "        fitters_results_2.append(fr)\n",
    "    \n",
    "        print_dynamic(\n",
    "            'Image: {} - Initial error: {} - Final error: {}'\n",
    "            .format(j, fr.initial_error(), fr.final_error()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting loop, noise = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_fitters = len(fitters)\n",
    "legend_entries = ['ini'] + [str(100 * scale) + '%' for scale in sampling_scales]\n",
    "\n",
    "fitters_results_3 = []\n",
    "for j, image in enumerate(test_images):\n",
    "    \n",
    "    np.random.seed(j)\n",
    "    \n",
    "    gt_shape = image.landmarks['ibug_face_68_trimesh'].lms\n",
    "    initial_shape = fitters[0].noisy_shape_from_shape(gt_shape, noise_percentage=0.06)\n",
    "\n",
    "    for fitter in fitters:\n",
    "        \n",
    "        fr = fitter.fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "        fr.downscale = 0.5\n",
    "        fitters_results_3.append(fr)\n",
    "    \n",
    "        print_dynamic(\n",
    "            'Image: {} - Initial error: {} - Final error: {}'\n",
    "            .format(j, fr.initial_error(), fr.final_error()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce combind mean error vs standard deviation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitters_results = [fitters_results_0,\n",
    "                   fitters_results_1,\n",
    "                   fitters_results_2,\n",
    "                   fitters_results_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_errors = []\n",
    "std_errors = []\n",
    "median_errors = []\n",
    "\n",
    "for frs in fitters_results:\n",
    "\n",
    "    errors = []\n",
    "    for j in range(n_fitters):\n",
    "        errors_j = []\n",
    "        for fr in frs[j::n_fitters]:\n",
    "            error = compute_normalise_point_to_point_error(fr.final_shape.points[17:, :], \n",
    "                                                           fr.gt_shape.points[17:, :],\n",
    "                                                           norm_shape=fr.gt_shape.points)\n",
    "            errors_j.append(error)\n",
    "        errors.append(errors_j)\n",
    "\n",
    "    mean_errs = []\n",
    "    std_errs = []\n",
    "    median_errs = []\n",
    "    for j in range(n_fitters):\n",
    "        errs = np.asarray(errors[j])\n",
    "        mean_errs.append(np.mean(errs))\n",
    "        std_errs.append(np.std(errs))\n",
    "        median_errs.append(np.median(errs))\n",
    "    \n",
    "    mean_errors.append(mean_errs)\n",
    "    std_errors.append(std_errs)\n",
    "    median_errors.append(median_errs)\n",
    "    \n",
    "mean_errors_matrix = np.asarray(mean_errors).T\n",
    "std_errors_matrix = np.asarray(std_errors).T\n",
    "median_errors_matrix = np.asarray(median_errors).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "res = ax.imshow(np.array(mean_errors_matrix), cmap=plt.cm.jet, \n",
    "                alpha=0.5, interpolation='nearest')\n",
    "\n",
    "height, width = mean_errors_matrix.shape\n",
    "\n",
    "\n",
    "\n",
    "for x in xrange(width):\n",
    "    for y in xrange(height):\n",
    "        ax.annotate(\"{0:.4f} ({0:.4f})\".format(mean_errors_matrix[x][y], std_errors_matrix[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "\n",
    "cb = fig.colorbar(res)\n",
    "x_axis_labels = ['0%', '1%', '4%', '6%']\n",
    "y_axis_labels = ['12.5%', '25%', '50%', '100%']\n",
    "plt.xticks(range(width), x_axis_labels[:width])\n",
    "plt.yticks(range(height), y_axis_labels[:height])\n",
    "plt.xlabel('Uniform noise')\n",
    "plt.ylabel('Sampling rate')\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig('/Users/joan/PhD/Results/alabort_aam_2015/noise_vs_sampling_ssd_bidirectional.png', \n",
    "            format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the speed of each fitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 fr = fitters[0].fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "%timeit -n 10 fr = fitters[1].fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "%timeit -n 10 fr = fitters[2].fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "%timeit -n 10 fr = fitters[3].fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a particular level of noise: \n",
    "\n",
    "1) visualize fitting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitters_results = fitters_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_fitting_result(fitters_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Produce CED graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = [[]]\n",
    "for fr in fitters_results[::n_fitters]:\n",
    "    error = compute_normalise_point_to_point_error(fr.initial_shape.points[17:, :], \n",
    "                                                   fr.gt_shape.points[17:, :],\n",
    "                                                   norm_shape=fr.gt_shape.points)\n",
    "    errors[0].append(error)\n",
    "\n",
    "for j in range(n_fitters):\n",
    "    errors_j = []\n",
    "    for fr in fitters_results[j::n_fitters]:\n",
    "        error = compute_normalise_point_to_point_error(fr.final_shape.points[17:, :], \n",
    "                                                       fr.gt_shape.points[17:, :],\n",
    "                                                       norm_shape=fr.gt_shape.points)\n",
    "        errors_j.append(error)\n",
    "    errors.append(errors_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ced(errors, legend_entries=legend_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Produce fitting statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j, e in enumerate(errors):\n",
    "    print legend_entries[j], '\\tmean:{0:.4f}'.format(np.mean(e)), '\\tstd:{0:.4f}'.format(np.std(e)), '\\tmedian:{0:.4f}'.format(np.median(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Produce mean and median error convergence graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_errors = []\n",
    "std_errors = []\n",
    "median_errors = []\n",
    "for j in range(n_fitters):\n",
    "    errors = []\n",
    "    for fr in fitters_results[j::n_fitters]:\n",
    "        errs = []\n",
    "        for shape in fr.shapes:\n",
    "            err = compute_normalise_point_to_point_error(shape.points[17:, :], \n",
    "                                                         fr.gt_shape.points[17:, :],\n",
    "                                                          norm_shape=fr.gt_shape.points)\n",
    "            errs.append(err)\n",
    "        errors.append(errs)\n",
    "    mean_errors.append(np.mean(errors, axis=0))\n",
    "    std_errors.append(np.std(errors, axis=0))\n",
    "    median_errors.append(np.median(errors, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colours = sample_colours_from_colourmap(n_fitters, 'jet')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    plt.plot(np.arange(0, len(mean_errors[i])),\n",
    "             mean_errors[i],\n",
    "             color=colours[i],\n",
    "             marker='o',\n",
    "             markersize=10,\n",
    "             linewidth=1.5)\n",
    "    \n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Normalized point-to-point error')\n",
    "plt.xlim((0, len(mean_errors[i]) - 1))\n",
    "plt.ylim((0.01, 0.08))\n",
    "plt.legend(legend_entries[1:])\n",
    "plt.grid(True)\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig('/Users/joan/PhD/Results/alabort_aam_2015/mean_error_vs_iters_ssd_bidirectional_0.04.png', \n",
    "            format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colours = sample_colours_from_colourmap(n_fitters, 'jet')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    plt.plot(np.arange(0, len(mean_errors[i])),\n",
    "             median_errors[i],\n",
    "             '--',\n",
    "             color=colours[i],\n",
    "             marker='^',\n",
    "             markersize=10,\n",
    "             linewidth=1.5)\n",
    "    \n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Normalized point-to-point error')\n",
    "plt.xlim((0, len(mean_errors[i]) - 1))\n",
    "plt.ylim((0.01, 0.08))\n",
    "plt.legend(legend_entries[1:])\n",
    "plt.grid(True)\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig('/Users/joan/PhD/Results/alabort_aam_2015/median_error_vs_iters_ssd_bidirectional_0.04.png', \n",
    "            format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# colours = sample_colours_from_colourmap(n_fitters, 'jet')\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.hold(True)\n",
    "\n",
    "# for i in range(len(mean_errors)):\n",
    "#     plt.errorbar(np.arange(0, len(mean_errors[i])), \n",
    "#                  mean_errors[i], \n",
    "#                  yerr=0.1 * std_errors[i],\n",
    "#                  color=colours[i],\n",
    "#                  marker='o',\n",
    "#                  markersize=10,\n",
    "#                  linewidth=1.5)\n",
    "#     plt.fill_between(np.arange(0, len(mean_errors[i])), \n",
    "#                      mean_errors[i] - 0.1 * std_errors[i], \n",
    "#                      mean_errors[i] + 0.1 * std_errors[i],\n",
    "#                      color=colours[i],\n",
    "#                      alpha=0.1)\n",
    "#     plt.plot(np.arange(0, len(mean_errors[i])),\n",
    "#              median_errors[i],\n",
    "#              '--',\n",
    "#              color=colours[i],\n",
    "#              marker='^',\n",
    "#              markersize=10,\n",
    "#              linewidth=1,\n",
    "#              alpha=0.75)\n",
    "    \n",
    "# plt.xlabel('Normalized point-to-point error')\n",
    "# plt.ylabel('Number of iterations')\n",
    "# plt.xlim((0, len(mean_errors[i]) - 1))\n",
    "# plt.legend(['12.5%', '12.5%', \n",
    "#             '25%', '25%', \n",
    "#             '50%', '50%', \n",
    "#             '100%', '100%',  ])\n",
    "\n",
    "# fig.set_size_inches(1.5*fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import line_profiler\n",
    "# import IPython\n",
    "\n",
    "# ip = IPython.get_ipython()\n",
    "# ip.define_magic('lprun', line_profiler.magic_lprun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %lprun -f ProjectOutAsymmetricGaussNewton._solve fitter_3.fit_from_shape(i, s, gt_shape=gt_s, max_iters=2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
