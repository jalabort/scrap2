{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "from functools import partial\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.feature import imgfeature, fast_dsift\n",
    "from menpo.landmark import labeller, ibug_face_68_trimesh\n",
    "from menpo.visualize import visualize_images, print_dynamic, plot_graph\n",
    "from menpo.visualize.viewmatplotlib import sample_colours_from_colourmap\n",
    "\n",
    "from menpofit.result import compute_normalise_point_to_point_error, compute_cumulative_error\n",
    "from menpofit.aam import (\n",
    "    HolisticAAM, LucasKanadeAAMFitter, \n",
    "    holistic_sampling_from_scale,  holistic_sampling_from_step)\n",
    "from menpofit.aam.algorithm.lk_alabort_arxiv2015 import (\n",
    "    SSDForwardWiberg,\n",
    "    SSDInverseWiberg,\n",
    "    SSDAsymmetricWiberg,\n",
    "    SSDBidirectionalWiberg)\n",
    "from menpofit.visualize import visualize_fitting_result, plot_ced, print_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@imgfeature\n",
    "def fast_dsift2(image):\n",
    "    if image.n_channels == 3:\n",
    "        image = image.as_greyscale(mode='average')\n",
    "    return fast_dsift(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_folder = '/Users/joan/PhD/DataBases/faces/'\n",
    "model_folder = '/Users/joan/PhD/Papers/alabort_arxiv2015_aam/experiments/'\n",
    "result_name = model_folder + 'algorithms/ssd_w/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aam = mio.import_pickle(model_folder + 'aam.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for i in mio.import_images(image_folder + 'lfpw/testset/', \n",
    "                           verbose=True, max_images=None):    \n",
    "    i = i.rescale_landmarks_to_diagonal_range(200)\n",
    "    i = i.crop_to_landmarks_proportion(0.5)\n",
    "    labeller(i, 'PTS', ibug_face_68_trimesh)\n",
    "    if i.n_channels == 3:\n",
    "        test_images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Active Appearance Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_shape = [3, 12]\n",
    "n_appearance = 0.75\n",
    "max_iters = [24, 16]\n",
    "scale = 0.5\n",
    "noise_percentage = 0.05\n",
    "\n",
    "repeat = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampling_step_1, sampling_mask_1 = holistic_sampling_from_scale(aam.appearance_models[0].mean(), \n",
    "                                                                scale=np.minimum(2 * scale, 1))\n",
    "\n",
    "sampling_mask_1.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampling_step_2, sampling_mask_2 = holistic_sampling_from_scale(aam.appearance_models[1].mean(), scale=scale)\n",
    "\n",
    "sampling_mask_2.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampling_step = [sampling_step_1, sampling_step_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAM Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algorithms = [SSDForwardWiberg,\n",
    "              SSDInverseWiberg,\n",
    "              SSDAsymmetricWiberg,\n",
    "              SSDBidirectionalWiberg]\n",
    "\n",
    "fitters = []\n",
    "for algorithm in algorithms:\n",
    "\n",
    "    fitter = LucasKanadeAAMFitter(\n",
    "        aam, \n",
    "        lk_algorithm_cls=partial(algorithm),\n",
    "        n_shape=n_shape, \n",
    "        n_appearance=n_appearance,\n",
    "        sampling=sampling_step)\n",
    "    \n",
    "    fitters.append(fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm_0 = fitter.aam.shape_models[0]\n",
    "sm_1 = fitter.aam.shape_models[1]\n",
    "\n",
    "print '1st scale -> \\tvariance:', sm_0.variance_ratio(), '\\tcomponents:', sm_0.n_active_components\n",
    "print '2nd scale -> \\tvariance:', sm_1.variance_ratio(), '\\tcomponents:', sm_1.n_active_components\n",
    "\n",
    "am_0 = fitter.aam.appearance_models[0]\n",
    "am_1 = fitter.aam.appearance_models[1]\n",
    "\n",
    "print '1st scale -> \\tvariance:', am_0.variance_ratio(), '\\tcomponents:', am_0.n_active_components\n",
    "print '2nd scale -> \\tvariance:', am_1.variance_ratio(), '\\tcomponents:', am_1.n_active_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fitters = len(fitters)\n",
    "legend_entries = ['Initialization', \n",
    "                  'SSD_For_W',\n",
    "                  'SSD_Inv_W',\n",
    "                  'SSD_Asy_W',\n",
    "                  'SSD_Bid_W']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitters_results = []\n",
    "for j, image in enumerate(repeat * test_images):\n",
    "    \n",
    "    np.random.seed(j)\n",
    "    \n",
    "    gt_shape = image.landmarks['ibug_face_68_trimesh'].lms\n",
    "    initial_shape = fitters[0].noisy_shape_from_shape(gt_shape, noise_percentage=noise_percentage, rotation=True)\n",
    "\n",
    "    for fitter in fitters:\n",
    "        \n",
    "        fr = fitter.fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) \n",
    "        fr.downscale = 0.5\n",
    "        fitters_results.append(fr.as_serializableresult())\n",
    "    \n",
    "        print_dynamic(\n",
    "            'Image: {} - Initial error: {} - Final error: {}'\n",
    "            .format(j, fr.initial_error(), fr.final_error()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mio.export_pickle(fitters_results, result_name + 'ssd_w.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fitters_results = mio.import_pickle(result_name + 'ssd_w.pkl.gz')\n",
    "\n",
    "# n_fitters = 4\n",
    "# legend_entries = ['Initialization', \n",
    "#                   'SSD_For_W',\n",
    "#                   'SSD_Inv_W',\n",
    "#                   'SSD_Asy_W',\n",
    "#                   'SSD_Bid_W']\n",
    "# max_iters = [24, 16]\n",
    "# noise_percentage = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce CED graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = [[]]\n",
    "for fr in fitters_results[::n_fitters]:\n",
    "    error = compute_normalise_point_to_point_error(fr.initial_shape.points[17:, :], \n",
    "                                                   fr.gt_shape.points[17:, :],\n",
    "                                                   norm_shape=fr.gt_shape.points)\n",
    "    errors[0].append(error)\n",
    "\n",
    "for j in range(n_fitters):\n",
    "    errors_j = []\n",
    "    for fr in fitters_results[j::n_fitters]:\n",
    "        error = compute_normalise_point_to_point_error(fr.final_shape.points[17:, :], \n",
    "                                                       fr.gt_shape.points[17:, :],\n",
    "                                                       norm_shape=fr.gt_shape.points)\n",
    "        errors_j.append(error)\n",
    "    errors.append(errors_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_axis =  np.arange(0, 0.052, 0.002)\n",
    "\n",
    "cumulative_errors = []\n",
    "for err in errors:\n",
    "    cumulative_errors.append(compute_cumulative_error(err, x_axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colours = ['black'] + sample_colours_from_colourmap(len(errors)-1, 'rainbow')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "for i in range(len(errors)):\n",
    "    plt.plot(x_axis,\n",
    "             cumulative_errors[i],\n",
    "             color=colours[i],\n",
    "             linewidth=4,\n",
    "             marker='s',\n",
    "             mec=colours[i],\n",
    "             mfc='w',\n",
    "             markersize=10,\n",
    "             mew=4)\n",
    "    \n",
    "plt.xlabel('Normalized point-to-point error')\n",
    "plt.ylabel('Proportion of images')\n",
    "plt.xlim((x_axis[0], x_axis[-1]))\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(legend_entries, loc=2)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.title('LFPW - {}% uniform noise '.format(int(100*noise_percentage)))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig(result_name + 'ced_ssd_w_{}.png'.format(int(100*noise_percentage)), \n",
    "            format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce fitting statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j, e in enumerate(errors):\n",
    "    print '{} \\tmean: {:.3f} \\tstd: {:.3f} \\tmedian: {:.3f}'.format(\n",
    "        legend_entries[j], np.mean(e), np.std(e), np.median(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j, e in enumerate(cumulative_errors):\n",
    "    print '{} \\t<0.02: {:.3f} \\t<0.03: {:.3f} \\t<0.04: {:.3f}'.format(\n",
    "        legend_entries[j], e[10], e[15], e[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce mean and median error convergence graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_errors = []\n",
    "std_errors = []\n",
    "median_errors = []\n",
    "for j in range(n_fitters):\n",
    "    errors = []\n",
    "    for fr in fitters_results[j::n_fitters]:\n",
    "        errs = []\n",
    "        for shape in fr.shapes:\n",
    "            err = compute_normalise_point_to_point_error(shape.points[17:, :], \n",
    "                                                         fr.gt_shape.points[17:, :],\n",
    "                                                         norm_shape=fr.gt_shape.points)            \n",
    "            errs.append(err)\n",
    "        while len(errs) < np.sum(max_iters) + 2:\n",
    "            errs.append(errs[-1])\n",
    "        errors.append(errs)\n",
    "    mean_errors.append(np.mean(errors, axis=0))\n",
    "    std_errors.append(np.std(errors, axis=0))\n",
    "    median_errors.append(np.median(errors, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colours = sample_colours_from_colourmap(n_fitters, 'rainbow')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    plt.plot(np.arange(0, len(mean_errors[i])),\n",
    "             mean_errors[i],\n",
    "             color=colours[i],\n",
    "             linewidth=4,\n",
    "             marker='o',\n",
    "             mec=colours[i],\n",
    "             mfc='w',\n",
    "             markersize=10,\n",
    "             mew=4)\n",
    "    \n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Mean normalized point-to-point error')\n",
    "plt.xlim((0, len(mean_errors[i]) - 1))\n",
    "plt.ylim((0.02, 0.09))\n",
    "plt.grid(True)\n",
    "plt.legend(legend_entries[1:])\n",
    "\n",
    "xs = (max_iters[0] + 1 , max_iters[0] + 1)\n",
    "ys = (0.02, 0.09)\n",
    "plt.plot(xs, ys, 'k--', lw=3)\n",
    "\n",
    "plt.title('LFPW - {}% uniform noise '.format(int(100*noise_percentage)))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig(result_name + 'mean_error_vs_iters_ssd_w_{}.png'.format(int(100*noise_percentage)),  \n",
    "            format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce mean and median cost convergence graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_costs = []\n",
    "std_costs = []\n",
    "median_costs = []\n",
    "for j in range(n_fitters):\n",
    "    costs = []\n",
    "    for fr in fitters_results[j::n_fitters]:\n",
    "        cost = list(fr.costs[:max_iters[0]+1] / fr.costs[0])\n",
    "        while len(cost) < np.sum(max_iters[0]) + 1:\n",
    "            cost.append(cost[-1])\n",
    "        costs.append(cost)\n",
    "    costs = np.asarray(costs)\n",
    "    mean_costs.append(np.mean(costs, axis=0))\n",
    "    std_costs.append(np.std(costs, axis=0))\n",
    "    median_costs.append(np.median(costs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from menpo.visualize.viewmatplotlib import sample_colours_from_colourmap\n",
    "\n",
    "colours = sample_colours_from_colourmap(n_fitters, 'rainbow')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "\n",
    "for i in range(len(mean_costs)):\n",
    "    plt.plot(np.arange(0, len(mean_costs[i])),\n",
    "             mean_costs[i],\n",
    "             color=colours[i],\n",
    "             linewidth=4,\n",
    "             marker='^',\n",
    "             mec=colours[i],\n",
    "             mfc='w',\n",
    "             markersize=10,\n",
    "             mew=4)\n",
    "    \n",
    "plt.xlabel('Number of iterations - First scale')\n",
    "plt.ylabel('Mean normalized cost')\n",
    "plt.xlim((0, len(mean_costs[i]) - 1))\n",
    "#plt.ylim((0.75, 1))\n",
    "plt.grid(True)\n",
    "plt.legend(legend_entries[1:])\n",
    "\n",
    "plt.title('LFPW - {}% uniform noise '.format(int(100*noise_percentage)))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig(result_name + 'mean_cost_vs_iters1_ssd_w_{}.png'.format(int(100*noise_percentage)), \n",
    "            format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_costs = []\n",
    "std_costs = []\n",
    "median_costs = []\n",
    "max_costs = np.zeros(len(fitters_results[0::n_fitters]))\n",
    "for j in range(n_fitters):\n",
    "    costs = []\n",
    "    for k, fr in enumerate(fitters_results[j::n_fitters]):\n",
    "        if max_costs[k] < fr.costs[max_iters[0] + 1:][0]:\n",
    "            max_costs[k] = fr.costs[max_iters[0] + 1:][0]\n",
    "        cost = list(fr.costs[max_iters[0] + 1:])\n",
    "        while len(cost) < max_iters[1] + 1:\n",
    "            cost.append(cost[-1])\n",
    "        costs.append(cost)\n",
    "    costs = np.asarray(costs) / max_costs[..., None]\n",
    "    mean_costs.append(np.mean(costs, axis=0))\n",
    "    std_costs.append(np.std(costs, axis=0))\n",
    "    median_costs.append(np.median(costs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from menpo.visualize.viewmatplotlib import sample_colours_from_colourmap\n",
    "\n",
    "colours = sample_colours_from_colourmap(n_fitters, 'rainbow')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "\n",
    "for i in range(len(mean_costs)):\n",
    "    plt.plot(np.arange(max_iters[0] + 1, np.sum(max_iters)+2),\n",
    "             mean_costs[i],\n",
    "             color=colours[i],\n",
    "             linewidth=4,\n",
    "             marker='^',\n",
    "             mec=colours[i],\n",
    "             mfc='w',\n",
    "             markersize=10,\n",
    "             mew=4)\n",
    "    \n",
    "plt.xlabel('Number of iterations - Second scale')\n",
    "plt.ylabel('Mean normalized cost')\n",
    "plt.xlim((max_iters[0] + 1, np.sum(max_iters)+1))\n",
    "#plt.ylim((0.82, 1.0))\n",
    "plt.grid(True)\n",
    "plt.legend(legend_entries[1:])\n",
    "\n",
    "plt.title('LFPW - {}% uniform noise '.format(int(100*noise_percentage)))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig.set_size_inches(2 * fig.get_size_inches())\n",
    "\n",
    "plt.savefig(result_name + 'mean_cost_vs_iters2_ssd_w_{}.png'.format(int(100*noise_percentage)), \n",
    "            format='png', dpi=300,  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit fr = fitters[0].fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=max_iters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For a particular algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_fitting_result(fitters_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import line_profiler\n",
    "# import IPython\n",
    "\n",
    "# ip = IPython.get_ipython()\n",
    "# ip.define_magic('lprun', line_profiler.magic_lprun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %lprun -f ProjectOutBidirectionalWiberg._solve fitters[0].fit_from_shape(image, initial_shape, gt_shape=gt_shape, max_iters=2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
