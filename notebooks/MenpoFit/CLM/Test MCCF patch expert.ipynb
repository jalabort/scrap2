{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.feature import no_op, fast_dsift\n",
    "from menpo.landmark import labeller, ibug_face_66\n",
    "from menpo.visualize import visualize_images\n",
    "from menpo.image import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MCCF patch expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by defining `centralize` and `normalize_norm` feature functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpo.feature import ndfeature\n",
    "\n",
    "@ndfeature\n",
    "def centralize(x, channels=True):\n",
    "    if channels:\n",
    "        m = np.mean(x, axis=(-2, -1))[..., None, None]\n",
    "    else:\n",
    "        m = np.mean(x)\n",
    "    \n",
    "    x = x - m\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "@ndfeature\n",
    "def normalize_norm(x, channels=True):\n",
    "    x = centralize(x, channels=channels)\n",
    "    \n",
    "    if channels:\n",
    "        norm = np.asarray(np.linalg.norm(x, axis=(-2, -1))[..., None, None])\n",
    "    else:\n",
    "        norm = np.asarray(np.linalg.norm(x))\n",
    "        \n",
    "    if np.any(norm == 0):\n",
    "        raise ValueError(\"Image has 0 variance - can't be normalized\")\n",
    "    else:\n",
    "        x = x / norm\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Channel Correlation Filters (MCCF) patch expert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pyfftw.interfaces.numpy_fft import fft2, fftshift\n",
    "from menpo.image import Image\n",
    "from menpofit.math.correlationfilter import mccf\n",
    "from menpofit.math.fft_utils import fft_convolve2d_sum\n",
    "\n",
    "class MCCFPatchExpert(object):\n",
    "    r\"\"\"\n",
    "    Multi-Channel Correlation Filter patch expert\n",
    "    \"\"\"\n",
    "    def __init__(self, l=1, normalize_callable=normalize_norm,\n",
    "                 cosine_mask=True, boundary='constant'):\n",
    "        self.l = l\n",
    "        self.normalize_callable = normalize_callable\n",
    "        self.cosine_mask = cosine_mask\n",
    "        self.boundary = boundary\n",
    "\n",
    "    def train(self, X, t):\n",
    "        # number of samples, number of channels, height and width\n",
    "        n, k, h, w = X.shape\n",
    "\n",
    "        if self.cosine_mask:\n",
    "            # compute cosine mask if required\n",
    "            cy = np.hanning(h)\n",
    "            cx = np.hanning(w)\n",
    "            self.cosine_mask = cy[..., None].dot(cx[None, ...])\n",
    "\n",
    "        # for each sample\n",
    "        keep = []\n",
    "        count = 0\n",
    "        X = deepcopy(X)\n",
    "        for j, x in enumerate(X):\n",
    "            try:\n",
    "                # normalize it if required\n",
    "                x = self.normalize_callable(x)\n",
    "                # apply cosine mask if required\n",
    "                if self.cosine_mask is not None:\n",
    "                    x = self.cosine_mask * x\n",
    "                X[count] = x\n",
    "                keep.append(j)\n",
    "                count += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        X = X[:count]\n",
    "\n",
    "        # compute correlation filter\n",
    "        self.filter = mccf(X, t, l=self.l, boundary=self.boundary)[0]\n",
    "        self.rescaled_filter = Image(self.filter).rescale(0.5).pixels\n",
    "        \n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def spatial_filter_image(self):\n",
    "        return Image(self.filter[:, ::-1, ::-1])\n",
    "\n",
    "    @property\n",
    "    def frequency_filter_image(self):\n",
    "        return Image(np.abs(fftshift(fft2(self.filter[:, ::-1, ::-1]))))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # normalize if required\n",
    "        x = self.normalize_callable(x)\n",
    "        # compute filter response\n",
    "        return fft_convolve2d_sum(x, self.filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in mio.import_images('/vol/atlas/databases/lfpw/trainset/', \n",
    "                           verbose=True, max_images=100):\n",
    "    if i.n_channels == 3:\n",
    "        i = i.crop_to_landmarks_proportion(0.8)\n",
    "        i = i.rescale_landmarks_to_diagonal_range(200)\n",
    "        labeller(i, 'PTS', ibug_face_66)\n",
    "        images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shapes = [i.landmarks['ibug_face_66'].lms for i in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a MCCF patch expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from menpo.shape import PointCloud\n",
    "from menpofit.base import build_grid\n",
    "from menpofit.clm.patch_experts import check_context_size\n",
    "\n",
    "patch_size = (32, 32) \n",
    "context_size= 4\n",
    "sample_offsets = PointCloud([[0, 0], [0, 2], [2, 0], [2, 2]])\n",
    "covariance = 5\n",
    "landmark = 42\n",
    "\n",
    "# check parameters\n",
    "context_size = check_context_size(context_size, patch_size)\n",
    "\n",
    "# build desired response\n",
    "grid = build_grid(patch_size)\n",
    "response = multivariate_normal(mean=np.zeros(2), cov=covariance).pdf(grid)\n",
    "\n",
    "samples = []\n",
    "for (i, s) in zip(images, shapes):\n",
    "    # choose appropriate landmark\n",
    "    centre = PointCloud([s.points[landmark]])\n",
    "    # extract positive sample\n",
    "    p = i.extract_patches(centre, patch_size=context_size,\n",
    "                          sample_offsets=sample_offsets,\n",
    "                          as_single_array=True)[0]\n",
    "\n",
    "    # add positive sample to list\n",
    "    samples.append(p.reshape((-1,) + p.shape[-2:]))\n",
    "\n",
    "# turn list into ndarray\n",
    "samples = np.asarray(samples)\n",
    "# train patch experts\n",
    "patch_expert = MCCFPatchExpert(l=10, cosine_mask=None).train(samples, response[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize ideal response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(response).view(cmap_name='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_images = [Image(s) for s in samples]\n",
    "\n",
    "visualize_images(samples_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(patch_expert.filter).view_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize response on training patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_maps = [patch_expert.predict(Image(s)) for s in samples]\n",
    "\n",
    "visualize_images(response_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize responses on entire training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# response_maps = [patch_expert.predict(i) for i in images]\n",
    "\n",
    "# visualize_images(response_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpo.shape import PointCloud\n",
    "\n",
    "landmarks = [PointCloud(s.points[40:42,:])  for s in shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.clm.patch_experts import CorrelationFilterExpertEnsemble\n",
    "from menpo.shape import PointCloud\n",
    "\n",
    "cfee = CorrelationFilterExpertEnsemble(\n",
    "    patch_size=(17, 17),\n",
    "    context_size=(34, 34),\n",
    "    response_covariance=1,\n",
    "    sample_offsets=PointCloud([[0,0],[8,0],[0,8],[8,8],[-8,0],[0,-8],[-8,-8]]))\n",
    "\n",
    "cfee.train(images, landmarks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.clm.patch_experts import LinearSVMExpertEnsemble\n",
    "from menpo.shape import PointCloud\n",
    "\n",
    "cfee = LinearSVMExpertEnsemble(\n",
    "    images, \n",
    "    landmarks, \n",
    "    verbose=True,\n",
    "    patch_size=(17, 17),\n",
    "    context_size=(34, 34),\n",
    "    sample_offsets=PointCloud([[0,0],[8,0],[0,8],[8,8],[-8,0],[0,-8],[-8,-8]]))\n",
    "\n",
    "cfee.train(images, landmarks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(cfee.spatial_filter_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "for (image, landmark) in zip(images, landmarks):\n",
    "    response = Image(cfee.predict(image, landmark)[1])\n",
    "    responses.append(response)\n",
    "    \n",
    "visualize_images(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from functools import partial\n",
    "\n",
    "linear_svm = partial(svm.LinearSVC, class_weight='auto')\n",
    "linear_svm_fit = linear_svm().fit\n",
    "\n",
    "class linear_svm(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.svm = svm.LinearSVC(class_weight='auto')\n",
    "        \n",
    "    def __call__(self, X, t):\n",
    "        self.svm.fit(X, t)\n",
    "        return self.svm.coef_, self.svm.intercept_\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[2,3],[1,2],[3,4],[7,8],[5,6]])\n",
    "b = np.array([[1,2],[5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in b:\n",
    "    a = np.delete(a, c.reshape((1,2)), axis=0)\n",
    "    \n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.base import build_grid\n",
    "\n",
    "context_size = np.asarray((17, 17))\n",
    "positive_neighbourhood = np.asarray((1, 1))\n",
    "\n",
    "grid = build_grid(context_size)\n",
    "        \n",
    "positive_mask = np.require(np.zeros(context_size, dtype=np.bool))\n",
    "half_size = np.floor(context_size / 2)\n",
    "half_size = np.require(half_size, dtype=int)\n",
    "start = half_size - np.ceil(positive_neighbourhood - 1)\n",
    "end = half_size + np.ceil(positive_neighbourhood)\n",
    "positive_mask[start[0]:end[0], start[1]:end[1]] = True\n",
    "\n",
    "positive_sample_points = grid[positive_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_sample_step = (4, 4)\n",
    "\n",
    "negative_mask = np.require(np.zeros(context_size, dtype=np.bool))\n",
    "negative_mask[::negative_sample_step[0], ::negative_sample_step[1]] = True\n",
    "negative_mask = np.logical_and(negative_mask, ~positive_mask)\n",
    "\n",
    "negative_sample_points = grid[negative_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(negative_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
